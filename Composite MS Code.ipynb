{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ms\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girder Upsizing not possible (W36x925 reached)\n",
      "Add Concrete Topping \n",
      "Initial Infill: W12X16 [21] c= 1.25\n",
      "Initial Girder: W18X40 [74] c= 0.75\n",
      "Initial Deck and Topping: 1.5VL20 GA w/ 2in LWC\n",
      "Initial Peak Acceleration: 1.8144274820483888\n",
      "Initial Scaled EC: 17.74507435388889\n",
      "Mitigated Infill: W16X26 [40] c= 1\n",
      "Mitigated Girder: W24X55 [77] c= 0.75\n",
      "Mitigated Peak Acceleration: 0.4626367469995589\n",
      "Mitigated Scaled EC: 33.29122530944444\n"
     ]
    }
   ],
   "source": [
    "#INPUT DESIGN VARIABLES HERE\n",
    "Girder_Span=30 #Girder Span [ft], range: (10ft, 50ft)\n",
    "Infill_Span=30 #Infill Span [ft], range: (10ft, 50ft)\n",
    "NumInfill=2 #Number of Equally Spaced Infills, range: (1, 5)\n",
    "Conc_Type_num=1 #Concrete Type, range: (0: Normal Weight Concrete, 1: Light Weight Concrete)\n",
    "Deck_Type=1.5 #Deck Depth [in], range: (1.5, 2, 3)\n",
    "percent_comp=75 #Percent Composite Connection: range: (25, 80)\n",
    "\n",
    "#parametets\n",
    "Es = 29000.0 #[ksi]\n",
    "Fy = 50.0 #[ksi]\n",
    "f_prime_c = 4 #[ksi]\n",
    "Clear_Spans = 3\n",
    "Building_Use_num = 3\n",
    "\n",
    "def sizer_and_calc(Girder_Span, Infill_Span, NumInfill, Conc_Type_num, Deck_Type, Building_Use_num, percent_comp):\n",
    "\n",
    "\n",
    "    def mitigation_method(Additional_Topping):\n",
    "        infill_spacing = Girder_Span / (NumInfill + 1)\n",
    "        infill_spacing_rounded = ms.ceil(Girder_Span / (NumInfill + 1))\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        #----------------------Database Imports------------------------------\n",
    "        #-------------------------------------------------------------------- \n",
    "\n",
    "        #Read in databases\n",
    "        AISC_database = pd.read_csv('AISC STEEL MANUAL V16 (Modified) Sorted.csv', encoding='latin1')\n",
    "        Deck_database = pd.read_csv('DeckData.csv')\n",
    "\n",
    "        #Select only the W-Shapes\n",
    "        W_Shapes = AISC_database[(AISC_database['Type'] == 'W')] #& (AISC_database['Economic'] == 1)]\n",
    "\n",
    "        #Deck Data Pulled from 'DeckData.xlsx'\n",
    "        Deck_Type_Table = Deck_database['Deck Type']\n",
    "        Conc_Type_Table = Deck_database['Conc Type']\n",
    "        Total_Depth = Deck_database['Total']\n",
    "        Topping_Depth = Deck_database['Topping']\n",
    "        Deck_Gage = Deck_database['Deck Gage']\n",
    "        Clear_Span_1 = Deck_database['1Span']\n",
    "        Clear_Span_2 = Deck_database['2Span']\n",
    "        Clear_Span_3 = Deck_database['3Span']\n",
    "        Slab_Weight = Deck_database['Concrete + Deck (psf)']\n",
    "        Allow_Load_4ft = Deck_database['4ft']\n",
    "        Allow_Load_5ft = Deck_database['5ft']\n",
    "        Allow_Load_6ft = Deck_database['6ft']\n",
    "        Allow_Load_7ft = Deck_database['7ft']\n",
    "        Allow_Load_8ft = Deck_database['8ft']\n",
    "        Allow_Load_9ft = Deck_database['9ft']\n",
    "        Allow_Load_10ft = Deck_database['10ft']\n",
    "        Allow_Load_11ft = Deck_database['11ft']\n",
    "        Allow_Load_12ft = Deck_database['12ft']\n",
    "        Allow_Load_13ft = Deck_database['13ft']\n",
    "        Allow_Load_14ft = Deck_database['14ft']\n",
    "        Allow_Load_15ft = Deck_database['15ft']\n",
    "        Allow_Load_16ft = Deck_database['16ft']\n",
    "        Deck_Design = Deck_database['Design']\n",
    "        Deck_Weight = Deck_database['Deck Weight (psf)']\n",
    "\n",
    "        #Steel Member Data Pulled from '\"AISC STEEL MANUAL V16 (Modified) Sorted.csv\"\n",
    "        shape_label = np.array(W_Shapes['AISC_Manual_Label'])\n",
    "        SW = W_Shapes['W']\n",
    "        A = np.array(W_Shapes['A'])\n",
    "        d = np.array(W_Shapes['d']).astype(float)\n",
    "        bf_over_2tf = W_Shapes['bf/2tf']\n",
    "        Sx = W_Shapes['Sx'].astype(float)\n",
    "        T = W_Shapes['T'].astype(float)\n",
    "        Jc = W_Shapes['J'].astype(float)\n",
    "        rts = W_Shapes['rts'].astype(float)\n",
    "        ho = W_Shapes['ho'].astype(float)\n",
    "        Z = W_Shapes['Zx [in3]']\n",
    "        bf = W_Shapes['bf'].astype(float)\n",
    "        tf = W_Shapes['tf'].astype(float)\n",
    "        tw = W_Shapes['tw'].astype(float)\n",
    "        PhiMpx = W_Shapes['PhiMpx']\n",
    "        PhiBF = W_Shapes['PhiBF']\n",
    "        Lp = W_Shapes['Lp [ft]']\n",
    "        Lr = W_Shapes['Lr [ft]']\n",
    "        Ix = W_Shapes['Ix [in4]']\n",
    "        PhiVnx = W_Shapes['PhiVnx']\n",
    "        Economic = W_Shapes['Economic']\n",
    "        Groups = W_Shapes['Grouping #']\n",
    "        Ingroup = W_Shapes['# in Grouping']\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        #------------------------Deck Sizer----------------------------------\n",
    "        #--------------------------------------------------------------------\n",
    "\n",
    "        # Define dictionaries\n",
    "        span_data_dict = {\n",
    "            1: Clear_Span_1,\n",
    "            2: Clear_Span_2,\n",
    "            3: Clear_Span_3\n",
    "        }\n",
    "\n",
    "        load_data_dict = {\n",
    "            4: Allow_Load_4ft,\n",
    "            5: Allow_Load_5ft,\n",
    "            6: Allow_Load_6ft,\n",
    "            7: Allow_Load_7ft,\n",
    "            8: Allow_Load_8ft,\n",
    "            9: Allow_Load_9ft,\n",
    "            10: Allow_Load_10ft,\n",
    "            11: Allow_Load_11ft,\n",
    "            12: Allow_Load_12ft,\n",
    "            13: Allow_Load_13ft,\n",
    "            14: Allow_Load_14ft,\n",
    "            15: Allow_Load_15ft,\n",
    "            16: Allow_Load_16ft\n",
    "        }\n",
    "\n",
    "        Building_Use_dict = {\n",
    "            1: ('Paper Office', 11, 0.5, 50, 0.03),\n",
    "            2: ('Electronic Office', 7, 0.5, 50, 0.025),\n",
    "            3: ('Residence', 6, 0.5, 40, 0.02),\n",
    "            4: ('Assembly Area', 0, 0.5, 100, 0.02),\n",
    "            5: ('Shopping Mall', 0, 1.5, 100, 0.02) #Cut Shopping Malls\n",
    "        }\n",
    "        Building_Use, live_load_vibrations, tolerance_limit, LL, DR = Building_Use_dict.get(Building_Use_num, ('', '', '', ''))\n",
    "\n",
    "        \n",
    "        if Conc_Type_num == 0:\n",
    "            Conc_Type = 'NW'\n",
    "            Conc_ECV = 0.133 #Concrete Embodied Carbon Value\n",
    "            conc_density = 145 #unit-weight of concrete [pcf]\n",
    "        else:\n",
    "            Conc_Type = 'LW'\n",
    "            Conc_ECV = 0.307 #Concrete Embodied Carbon Value\n",
    "            conc_density = 110 #unit-weight of concrete [pcf]\n",
    "\n",
    "        #This is additional Concrete load as a result of Additional Concrete Topping because the Vulcraft tables factor out concrete self weight of set thicknesses\n",
    "        if Conc_Type == 'NW':\n",
    "            Additional_Topping_Load = 145 * (Additional_Topping / 12) #[psf]\n",
    "        if Conc_Type == 'LW':\n",
    "            Additional_Topping_Load = 110 * (Additional_Topping / 12) #[psf]\n",
    "        \n",
    "        # Superimposed Dead Load [psf]\n",
    "        SDL = 20 #Assumed for each building use\n",
    "        Conc_Load = LL + SDL + Additional_Topping_Load\n",
    "\n",
    "        # Concrete Type Check\n",
    "        if len(Conc_Type) != len(Conc_Type_Table):\n",
    "            Conc_Type = list(repeat(Conc_Type, 90))\n",
    "        Conc_Type_Check = Conc_Type == Conc_Type_Table\n",
    "\n",
    "        # Deck Type Check\n",
    "        Deck_Type_Check = Deck_Type == Deck_Type_Table\n",
    "\n",
    "        # Span Check\n",
    "        Span_Data = span_data_dict.get(Clear_Spans)\n",
    "        Span_Check = Span_Data >= infill_spacing\n",
    "\n",
    "        # Span Check\n",
    "        if infill_spacing_rounded < 4:\n",
    "            infill_spacing_rounded = 4\n",
    "        Load_Data = load_data_dict.get(infill_spacing_rounded)\n",
    "        if Load_Data is None:\n",
    "            print(\"No deck can be sized\")\n",
    "            deck_pass_or_fail = 0  # fails\n",
    "            return\n",
    "        elif Load_Data.empty:\n",
    "            print(\"Load Data is empty\")\n",
    "            deck_pass_or_fail = 0  # fails\n",
    "            return\n",
    "        else:\n",
    "            deck_pass_or_fail = 1  # passes\n",
    "\n",
    "        Load_Check = Conc_Load <= Load_Data\n",
    "\n",
    "        # Set Intersection of all deck checks\n",
    "        Deck_Check = Conc_Type_Check & Deck_Type_Check & Span_Check & Load_Check\n",
    "\n",
    "        # Filter Decks based on Deck_Check\n",
    "        filtered_Decks = Deck_database[Deck_Check]\n",
    "        \n",
    "        # Check if filtered_Decks is empty\n",
    "        if filtered_Decks.empty:\n",
    "            print(\"No deck can be sized\")\n",
    "            deck_pass_or_fail = 0 #fails\n",
    "            return\n",
    "        else:\n",
    "            deck_pass_or_fail = 1 #passes\n",
    "        \n",
    "        # Select Lightest Deck\n",
    "        lowest_Slab_Weight = filtered_Decks['Concrete + Deck (psf)'].idxmin()\n",
    "        deck_pass_or_fail = []\n",
    "        selected_deck = filtered_Decks.loc[lowest_Slab_Weight, 'Design']\n",
    "\n",
    "        # New Slab Weight\n",
    "        selected_deck_slab_SW = filtered_Decks.loc[lowest_Slab_Weight, 'Concrete + Deck (psf)']\n",
    "        Final_Slab_SW = selected_deck_slab_SW + Additional_Topping_Load\n",
    "\n",
    "        # New Slab Thickness\n",
    "        selected_deck_slab_thickness = filtered_Decks.loc[lowest_Slab_Weight, 'Total'] \n",
    "        selected_deck_topping_thickness = filtered_Decks.loc[lowest_Slab_Weight, 'Topping'] # Selected Topping Thickness without Addtional [in]\n",
    "        selected_deck_thickness = filtered_Decks.loc[lowest_Slab_Weight, 'Deck Type'] # Selected Deck Thickness [in]\n",
    "        selected_deck_SW = filtered_Decks.loc[lowest_Slab_Weight, 'Deck Weight (psf)']\n",
    "        Final_Slab_Thickness = selected_deck_topping_thickness + Additional_Topping # Total Selected Slab Thickness [in]\n",
    "        Final_Deck_Slab_Thickness = Final_Slab_Thickness + selected_deck_thickness # Total Selected Floor System Thicknes [in]\n",
    "        \n",
    "        #New Dead Load\n",
    "        DL = Final_Slab_SW + SDL\n",
    "\n",
    "        #Average Concrete Depth in Flute\n",
    "        if Deck_Type == 1.5:\n",
    "            Conc_Depth_in_Flute = 0.532414\n",
    "        if Deck_Type == 2:\n",
    "            Conc_Depth_in_Flute = 1\n",
    "        if Deck_Type == 3:\n",
    "            Conc_Depth_in_Flute = 1.5\n",
    "        \n",
    "        effective_conc_depth = selected_deck_topping_thickness + Conc_Depth_in_Flute + Additional_Topping\n",
    "\n",
    "        #----------------------------------------------------------------------\n",
    "        #----------------------Composite Values--------------------------------\n",
    "        #----------------------------------------------------------------------\n",
    "\n",
    "        # Basic parameters\n",
    "        tc = selected_deck_topping_thickness\n",
    "        hr = Deck_Type\n",
    "\n",
    "        #------------------------Infill Values----------------------------------\n",
    "\n",
    "        A_II = np.array(A)[:, np.newaxis]\n",
    "        bf_II = np.array(bf)[:, np.newaxis]\n",
    "        tf_II = np.array(tf)[:, np.newaxis]\n",
    "        tw_II = np.array(tw)[:, np.newaxis]\n",
    "        Z_II = np.array(Z)[:, np.newaxis]\n",
    "        d_II = np.array(d)[:, np.newaxis]\n",
    "        Ix_II = np.array(Ix)[:, np.newaxis]\n",
    "\n",
    "        # Effective width calculation\n",
    "        b_eff_II = min(Infill_Span * 12 * 2 / 8, infill_spacing * 12 / 2 * 2)\n",
    "\n",
    "        # Force calculations\n",
    "        Vc_prime_II = np.array(0.85 * f_prime_c * b_eff_II * tc)\n",
    "        Vs_prime_II = np.array(A_II * Fy)\n",
    "        V_prime_II = np.array(np.minimum(Vc_prime_II, Vs_prime_II))\n",
    "\n",
    "        # Stud calculations\n",
    "        stud_dia_II = 0.75\n",
    "        studs_per_rib_II = np.expand_dims(np.array([1, 2, 3]), axis=(0, 1))\n",
    "        Rg_II = np.expand_dims(np.array([1.0, 0.85, 0.7]), axis=(0, 1))\n",
    "        Rp_II = 0.6\n",
    "        Fu_II = 65\n",
    "        A_stud_II = (ms.pi * stud_dia_II ** 2 / 4)\n",
    "        Ec_II = conc_density ** 1.5 * ms.sqrt(f_prime_c)\n",
    "        Qn_II = np.minimum(0.5 * A_stud_II * ms.sqrt(f_prime_c * Ec_II), Rg_II * Rp_II * A_stud_II * Fu_II)\n",
    "\n",
    "        # Stud count calculations\n",
    "        max_studs_half_II = np.floor(Infill_Span * studs_per_rib_II / 2)\n",
    "        max_PCC_II = np.minimum(max_studs_half_II * Qn_II / V_prime_II[:, np.newaxis] * 100, 100)\n",
    "        req_studs_half_II = percent_comp * V_prime_II[:, np.newaxis] / Qn_II / 100\n",
    "        req_studs_half_filter_II = np.where(max_studs_half_II <= req_studs_half_II, np.nan, req_studs_half_II)\n",
    "        req_studs_II = np.ceil(req_studs_half_filter_II * 2)\n",
    "        min_req_studs_II = np.nanmin(req_studs_II, axis=2)\n",
    "\n",
    "        # Minimum studs per rib calculation\n",
    "        min_studs_per_rib_II = np.where(min_req_studs_II == req_studs_II[:, :, 0], 1, np.nan)\n",
    "        min_studs_per_rib_II = np.where(min_req_studs_II == req_studs_II[:, :, 1], 2, min_studs_per_rib_II)\n",
    "        min_studs_per_rib_II = np.where(min_req_studs_II == req_studs_II[:, :, 2], 3, min_studs_per_rib_II)\n",
    "\n",
    "        stud_capacity_II = np.where(min_req_studs_II == req_studs_II[:, :, 0], req_studs_II[:, :, 0] * Qn_II[:, :, 0], np.nan)\n",
    "        stud_capacity_II = np.where(min_req_studs_II == req_studs_II[:, :, 1], req_studs_II[:, :, 1] * Qn_II[:, :, 1], stud_capacity_II)\n",
    "        stud_capacity_II = np.where(min_req_studs_II == req_studs_II[:, :, 2], req_studs_II[:, :, 2] * Qn_II[:, :, 2], stud_capacity_II)\n",
    "\n",
    "        selected_Qn_II = np.where(min_req_studs_II == req_studs_II[:, :, 0], Qn_II[:, :, 0], np.nan)\n",
    "        selected_Qn_II = np.where(min_req_studs_II == req_studs_II[:, :, 1], Qn_II[:, :, 1], selected_Qn_II)\n",
    "        selected_Qn_II = np.where(min_req_studs_II == req_studs_II[:, :, 2], Qn_II[:, :, 2], selected_Qn_II)\n",
    "\n",
    "        # 100% composite calculations\n",
    "        if percent_comp == 100:\n",
    "            Sigma_Qn_II = percent_comp / 100 * V_prime_II\n",
    "            Case_1_II = (Vs_prime_II <= Vc_prime_II)\n",
    "            a_1_II = np.minimum(tc, A_II * Fy / (0.85 * f_prime_c * b_eff_II))\n",
    "            Cc_1_II = 0.85 * f_prime_c * b_eff_II * a_1_II\n",
    "            Y2_1_II = Final_Deck_Slab_Thickness - a_1_II / 2\n",
    "            Phi_Mn_1_II = np.where(Case_1_II, 0.9 * (A_II * Fy * (d_II / 2 + Y2_1_II)) / 12, np.nan)\n",
    "\n",
    "            Cs_II = (A_II * Fy - Cc_1_II) / 2\n",
    "            Asc_II = np.array(Cs_II / Fy)\n",
    "            A_flange_II = np.array(bf_II * tf_II)\n",
    "\n",
    "            Case_2a_II = (Vs_prime_II > Vc_prime_II) & (Asc_II < A_flange_II)\n",
    "            Cc_2a_II = 0.85 * f_prime_c * b_eff_II * tc\n",
    "            T_2a_II = A_II * Fy\n",
    "            Y1_2a_II = (A_II * Fy - Cc_2a_II) / (2 * bf_II * Fy)\n",
    "            Y2_2a_II = hr + tc / 2\n",
    "            Phi_Mn_2a_II = np.where(Case_2a_II, 0.9 * (Cc_2a_II * (Y2_2a_II + Y1_2a_II / 2) + T_2a_II * (d_II / 2 - Y1_2a_II / 2)) / 12, np.nan)\n",
    "\n",
    "            Case_2b_II = (Vs_prime_II > Vc_prime_II) & (Asc_II >= A_flange_II)\n",
    "            Cc_2b_II = 0.85 * f_prime_c * b_eff_II * tc\n",
    "            Y1_2b_II = d_II / 2 - Cc_2b_II / (2 * tw_II * Fy)\n",
    "            Y2_2b_II = hr + tc / 2\n",
    "            Ts1_2b_II = 2 * tw_II * Fy * (d_II / 2 - Y1_2b_II)\n",
    "            Mp_2b_II = Fy * Z_II\n",
    "            Phi_Mn_2b_II = np.where(Case_2b_II, 0.9 * (Cc_2b_II * (Y2_2b_II + d_II / 2) - Ts1_2b_II * ((d_II / 2 - Y1_2b_II) / 2) + Mp_2b_II) / 12, np.nan)\n",
    "\n",
    "            Phi_Mn_II = np.nanmax(np.stack([Phi_Mn_1_II, Phi_Mn_2a_II, Phi_Mn_2b_II]), axis=0)\n",
    "\n",
    "            # Initialize Y1 and Y2\n",
    "            Y1_II = np.zeros_like(Case_1_II, dtype=float)\n",
    "            Y2_II = np.full_like(Case_1_II, np.nan, dtype=float)\n",
    "\n",
    "            Y1_II = np.where(Case_1_II, 0, Y1_II)\n",
    "            Y2_II = np.where(Case_1_II, Y2_1_II, Y2_II)\n",
    "\n",
    "            Y1_II = np.where(Case_2a_II, Y1_2a_II, Y1_II)\n",
    "            Y2_II = np.where(Case_2a_II, Y2_2a_II, Y2_II)\n",
    "\n",
    "            Y1_II = np.where(Case_2b_II, Y1_2b_II, Y1_II)\n",
    "            Y2_II = np.where(Case_2b_II, Y2_2b_II, Y2_II)\n",
    "\n",
    "            case_label_II = np.where(Case_1_II, 'Case 1', \n",
    "                np.where(Case_2a_II, 'Case 2a', \n",
    "                np.where(Case_2b_II, 'Case 2b', 'Unknown Case')))\n",
    "            \n",
    "        # partial composite calculation\n",
    "        elif 25 <= percent_comp < 100:\n",
    "            Sigma_Qn_II = percent_comp / 100 * V_prime_II\n",
    "            a_3_II = np.minimum(Sigma_Qn_II / (0.85 * f_prime_c * b_eff_II), tc)\n",
    "            Cc_3_II = np.minimum(Sigma_Qn_II, 0.85 * f_prime_c * b_eff_II * a_3_II)\n",
    "            Cs_3a_II = (A_II * Fy - Cc_3_II) / 2\n",
    "            T_3a_II = A_II * Fy\n",
    "            Y1_3a_II = (A_II * Fy - Cc_3_II) / (2 * bf_II * Fy)\n",
    "            Y2_3a_II = hr + tc - a_3_II / 2\n",
    "            Case_3a_II = Y1_3a_II <= tf_II\n",
    "            Phi_Mn_3a_II = np.where(Case_3a_II, 0.9 * (Cc_3_II * (Y2_3a_II + Y1_3a_II / 2) + T_3a_II * (d_II / 2 - Y1_3a_II / 2)) / 12, np.nan)\n",
    "\n",
    "            Y1_3b_II = d_II / 2 - Cc_3_II / (2 * tw_II * Fy)\n",
    "            Y2_3b_II = hr + tc / 2\n",
    "            Ts1_3b_II = 2 * tw_II * Fy * (d_II / 2 - Y1_3b_II)\n",
    "            Case_3b_II = Y1_3a_II > tf_II\n",
    "            Mp_3b_II = Fy * Z_II\n",
    "            Phi_Mn_3b_II = np.where(Case_3b_II, 0.9 * (Cc_3_II * (Y2_3b_II + d_II / 2) - Ts1_3b_II * ((d_II / 2 - Y1_3b_II) / 2) + Mp_3b_II) / 12, np.nan)\n",
    "\n",
    "            Phi_Mn_II = np.nanmax(np.stack([Phi_Mn_3a_II, Phi_Mn_3b_II]), axis=0)\n",
    "\n",
    "            # Initialize Y1 and Y2\n",
    "            Y1_II = np.zeros_like(Case_3a_II, dtype=float)\n",
    "            Y2_II = np.full_like(Case_3a_II, np.nan, dtype=float)\n",
    "\n",
    "            Y1_II = np.where(Case_3a_II, Y1_3a_II, Y1_II)\n",
    "            Y2_II = np.where(Case_3a_II, Y2_3a_II, Y2_II)\n",
    "\n",
    "            Y1_II = np.where(Case_3b_II, Y1_3b_II, Y1_II)\n",
    "            Y2_II = np.where(Case_3b_II, Y2_3b_II, Y2_II)\n",
    "\n",
    "            case_label_II = np.where(Case_3a_II, 'Case 3a', \n",
    "                np.where(Case_3b_II, 'Case 3b', 'Unknown Case'))\n",
    "\n",
    "        else:\n",
    "            num_studs_II = np.nan\n",
    "\n",
    "        # PCC check calculations\n",
    "        PCC_check_II = np.max(max_PCC_II >= percent_comp, axis=2)\n",
    "        Phi_Mn_filtered_II = np.where(PCC_check_II, Phi_Mn_II, np.nan)\n",
    "\n",
    "        # Lower Bound Moment of Inertia calculations\n",
    "        a_II = np.minimum(Sigma_Qn_II / (0.85 * f_prime_c * b_eff_II), tc)\n",
    "        d1_II = tc + hr - a_II / 2\n",
    "        d3_II = d_II/2\n",
    "        Y_ENA_II = (A_II * d3_II + (Sigma_Qn_II / Fy) * (2 * d3_II + d1_II)) / (A_II + (Sigma_Qn_II / Fy))\n",
    "        I_LB_II = Ix_II + A_II * (Y_ENA_II - d3_II) ** 2 + (Sigma_Qn_II / Fy) * (2 * d3_II + d1_II - Y_ENA_II) ** 2\n",
    "\n",
    "        #------------------------Girder Values----------------------------------\n",
    "\n",
    "        A_IG = np.array(A)[np.newaxis, :, np.newaxis]\n",
    "        bf_IG = np.array(bf)[np.newaxis, :, np.newaxis]\n",
    "        tf_IG = np.array(tf)[np.newaxis, :, np.newaxis]\n",
    "        tw_IG = np.array(tw)[np.newaxis, :, np.newaxis]\n",
    "        Z_IG = np.array(Z)[np.newaxis, :, np.newaxis]\n",
    "        d_IG = np.array(d)[np.newaxis, :, np.newaxis]\n",
    "        Ix_IG = np.array(Ix)[np.newaxis, :, np.newaxis]\n",
    "\n",
    "        # Effective width calculation\n",
    "        b_eff_IG = min(Girder_Span * 12 * 2 / 8, Infill_Span * 12 / 2 * 2)\n",
    "\n",
    "        # Force calculations\n",
    "        Vc_prime_IG = np.array(0.85 * f_prime_c * b_eff_IG * tc)\n",
    "        Vs_prime_IG = np.array(A_IG * Fy)\n",
    "        V_prime_IG = np.array(np.minimum(Vc_prime_IG, Vs_prime_IG))\n",
    "\n",
    "        # Stud calculations\n",
    "        stud_dia_IG = 0.75\n",
    "        studs_per_rib_IG = np.expand_dims(np.array([1, 2, 3]), axis=(0, 1))\n",
    "        Rg_IG = np.expand_dims(np.array([1.0, 0.85, 0.7]), axis=(0, 1))\n",
    "        Rp_IG = 0.6\n",
    "        Fu_IG = 65\n",
    "        A_stud_IG = (ms.pi * stud_dia_IG ** 2 / 4)\n",
    "        Ec_IG = conc_density ** 1.5 * ms.sqrt(f_prime_c)\n",
    "        Qn_IG = np.minimum(0.5 * A_stud_IG * ms.sqrt(f_prime_c * Ec_IG), Rg_IG * Rp_IG * A_stud_IG * Fu_IG)\n",
    "\n",
    "        # Stud count calculations\n",
    "        max_studs_half_IG = np.floor(Girder_Span * studs_per_rib_IG / 2)\n",
    "        max_PCC_IG = np.minimum(max_studs_half_IG * Qn_IG / V_prime_IG * 100, 100)\n",
    "        req_studs_half_IG = percent_comp * V_prime_IG / Qn_IG / 100\n",
    "        req_studs_half_filter_IG = np.where(max_studs_half_IG <= req_studs_half_IG, np.nan, req_studs_half_IG)\n",
    "        req_studs_IG = np.ceil(req_studs_half_filter_IG * 2)\n",
    "        min_req_studs_IG = np.nanmin(req_studs_IG, axis=2)\n",
    "\n",
    "        # Minimum studs per rib calculation\n",
    "        min_studs_per_rib_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 0], 1, np.nan)\n",
    "        min_studs_per_rib_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 1], 2, min_studs_per_rib_IG)\n",
    "        min_studs_per_rib_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 2], 3, min_studs_per_rib_IG)\n",
    "\n",
    "        stud_capacity_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 0], req_studs_IG[:, :, 0] * Qn_IG[:, :, 0], np.nan)\n",
    "        stud_capacity_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 1], req_studs_IG[:, :, 1] * Qn_IG[:, :, 1], stud_capacity_IG)\n",
    "        stud_capacity_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 2], req_studs_IG[:, :, 2] * Qn_IG[:, :, 2], stud_capacity_IG)\n",
    "\n",
    "        selected_Qn_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 0], Qn_IG[:, :, 0], np.nan)\n",
    "        selected_Qn_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 1], Qn_IG[:, :, 1], selected_Qn_IG)\n",
    "        selected_Qn_IG = np.where(min_req_studs_IG == req_studs_IG[:, :, 2], Qn_IG[:, :, 2], selected_Qn_IG)\n",
    "\n",
    "        # 100% composite calculations\n",
    "        if percent_comp == 100:\n",
    "            Sigma_Qn_IG = percent_comp / 100 * V_prime_IG\n",
    "            Case_1_IG = (Vs_prime_IG <= Vc_prime_IG)\n",
    "            a_1_IG = np.minimum(tc, A_IG * Fy / (0.85 * f_prime_c * b_eff_IG))\n",
    "            Cc_1_IG = 0.85 * f_prime_c * b_eff_IG * a_1_IG\n",
    "            Y2_1_IG = Final_Deck_Slab_Thickness - a_1_IG / 2\n",
    "            Phi_Mn_1_IG = np.where(Case_1_IG, 0.9 * (A_IG * Fy * (d_IG / 2 + Y2_1_IG)) / 12, np.nan)\n",
    "\n",
    "            Cs_IG = (A_IG * Fy - Cc_1_IG) / 2\n",
    "            Asc_IG = np.array(Cs_IG / Fy)\n",
    "            A_flange_IG = np.array(bf_IG * tf_IG)\n",
    "\n",
    "            Case_2a_IG = (Vs_prime_IG > Vc_prime_IG) & (Asc_IG < A_flange_IG)\n",
    "            Cc_2a_IG = 0.85 * f_prime_c * b_eff_IG * tc\n",
    "            T_2a_IG = A_IG * Fy\n",
    "            Y1_2a_IG = (A_IG * Fy - Cc_2a_IG) / (2 * bf_IG * Fy)\n",
    "            Y2_2a_IG = hr + tc / 2\n",
    "            Phi_Mn_2a_IG = np.where(Case_2a_IG, 0.9 * (Cc_2a_IG * (Y2_2a_IG + Y1_2a_IG / 2) + T_2a_IG * (d_IG / 2 - Y1_2a_IG / 2)) / 12, np.nan)\n",
    "\n",
    "            Case_2b_IG = (Vs_prime_IG > Vc_prime_IG) & (Asc_IG >= A_flange_IG)\n",
    "            Cc_2b_IG = 0.85 * f_prime_c * b_eff_IG * tc\n",
    "            Y1_2b_IG = d_IG / 2 - Cc_2b_IG / (2 * tw_IG * Fy)\n",
    "            Y2_2b_IG = hr + tc / 2\n",
    "            Ts1_2b_IG = 2 * tw_IG * Fy * (d_IG / 2 - Y1_2b_IG)\n",
    "            Mp_2b_IG = Fy * Z_IG\n",
    "            Phi_Mn_2b_IG = np.where(Case_2b_IG, 0.9 * (Cc_2b_IG * (Y2_2b_IG + d_IG / 2) - Ts1_2b_IG * ((d_IG / 2 - Y1_2b_IG) / 2) + Mp_2b_IG) / 12, np.nan)\n",
    "\n",
    "            Phi_Mn_IG = np.nanmax(np.stack([Phi_Mn_1_IG, Phi_Mn_2a_IG, Phi_Mn_2b_IG]), axis=0)\n",
    "\n",
    "            # Initialize Y1 and Y2 with default values\n",
    "            Y1_IG = np.zeros_like(Case_1_IG, dtype=float)\n",
    "            Y2_IG = np.full_like(Case_1_IG, np.nan, dtype=float)\n",
    "\n",
    "            Y1_IG = np.where(Case_1_IG, 0, Y1_IG)\n",
    "            Y2_IG = np.where(Case_1_IG, Y2_1_IG, Y2_IG)\n",
    "\n",
    "            Y1_IG = np.where(Case_2a_IG, Y1_2a_IG, Y1_IG)\n",
    "            Y2_IG = np.where(Case_2a_IG, Y2_2a_IG, Y2_IG)\n",
    "\n",
    "            Y1_IG = np.where(Case_2b_IG, Y1_2b_IG, Y1_IG)\n",
    "            Y2_IG = np.where(Case_2b_IG, Y2_2b_IG, Y2_IG)\n",
    "\n",
    "            case_label_IG = np.where(Case_1_IG, 'Case 1', \n",
    "                np.where(Case_2a_IG, 'Case 2a', \n",
    "                np.where(Case_2b_IG, 'Case 2b', 'Unknown Case')))\n",
    "\n",
    "        # partial composite calculations\n",
    "        elif 25 <= percent_comp < 100:\n",
    "            Sigma_Qn_IG = percent_comp / 100 * V_prime_IG\n",
    "            a_3_IG = np.minimum(Sigma_Qn_IG / (0.85 * f_prime_c * b_eff_IG), tc)\n",
    "            Cc_3_IG = np.minimum(Sigma_Qn_IG, 0.85 * f_prime_c * b_eff_IG * a_3_IG)\n",
    "            Cs_3a_IG = (A_IG * Fy - Cc_3_IG) / 2\n",
    "            T_3a_IG = A_IG * Fy\n",
    "            Y1_3a_IG = (A_IG * Fy - Cc_3_IG) / (2 * bf_IG * Fy)\n",
    "            Y2_3a_IG = hr + tc - a_3_IG / 2\n",
    "            Case_3a_IG = Y1_3a_IG <= tf_IG\n",
    "            Phi_Mn_3a_IG = np.where(Case_3a_IG, 0.9 * (Cc_3_IG * (Y2_3a_IG + Y1_3a_IG / 2) + T_3a_IG * (d_IG / 2 - Y1_3a_IG / 2)) / 12, np.nan)\n",
    "\n",
    "            Y1_3b_IG = d_IG / 2 - Cc_3_IG / (2 * tw_IG * Fy)\n",
    "            Y2_3b_IG = hr + tc / 2\n",
    "            Ts1_3b_IG = 2 * tw_IG * Fy * (d_IG / 2 - Y1_3b_IG)\n",
    "            Case_3b_IG = Y1_3a_IG > tf_IG\n",
    "            Mp_3b_IG = Fy * Z_IG\n",
    "            Phi_Mn_3b_IG = np.where(Case_3b_IG, 0.9 * (Cc_3_IG * (Y2_3b_IG + d_IG / 2) - Ts1_3b_IG * ((d_IG / 2 - Y1_3b_IG) / 2) + Mp_3b_IG) / 12, np.nan)\n",
    "\n",
    "            Phi_Mn_IG = np.nanmax(np.stack([Phi_Mn_3a_IG, Phi_Mn_3b_IG]), axis=0)\n",
    "\n",
    "            # Initialize Y1 and Y2\n",
    "            Y1_IG = np.zeros_like(Case_3a_IG, dtype=float)\n",
    "            Y2_IG = np.full_like(Case_3a_IG, np.nan, dtype=float)\n",
    "\n",
    "            Y1_IG = np.where(Case_3a_IG, Y1_3a_IG, Y1_IG)\n",
    "            Y2_IG = np.where(Case_3a_IG, Y2_3a_IG, Y2_IG)\n",
    "\n",
    "            Y1_IG = np.where(Case_3b_IG, Y1_3b_IG, Y1_IG)\n",
    "            Y2_IG = np.where(Case_3b_IG, Y2_3b_IG, Y2_IG)\n",
    "\n",
    "            case_label_IG = np.where(Case_3a_IG, 'Case 3a', \n",
    "                np.where(Case_3b_IG, 'Case 3b', 'Unknown Case'))\n",
    "\n",
    "        else:\n",
    "            print('PCC below 25% can not be composite')\n",
    "\n",
    "        # PCC check calculations\n",
    "        PCC_check_IG = max_PCC_IG >= percent_comp \n",
    "        PCC_check_flat_IG = np.max(max_PCC_IG, axis=2) >= percent_comp\n",
    "        Phi_Mn_filtered_IG = np.where(PCC_check_flat_IG, Phi_Mn_IG, np.nan)\n",
    "\n",
    "        # Lower Bound Moment of Inertia calculations\n",
    "        a_IG = np.minimum(Sigma_Qn_IG / (0.85 * f_prime_c * b_eff_IG), tc)\n",
    "        d1_IG = tc + hr - a_IG / 2\n",
    "        d3_IG = d_IG/2\n",
    "        Y_ENA_IG = (A_IG * d3_IG + (Sigma_Qn_IG / Fy) * (2 * d3_IG + d1_IG)) / (A_IG + (Sigma_Qn_IG / Fy))\n",
    "        I_LB_IG = Ix_IG + A_IG * (Y_ENA_IG - d3_IG) ** 2 + (Sigma_Qn_IG / Fy) * (2 * d3_IG + d1_IG - Y_ENA_IG) ** 2\n",
    "\n",
    "        # Need to flatten some IG variables used in later calcs\n",
    "        Phi_Mn_IG = Phi_Mn_IG.flatten()\n",
    "        I_LB_IG = I_LB_IG.flatten()\n",
    "        Y1_IG = Y1_IG.flatten()\n",
    "        Y2_IG = Y2_IG.flatten()\n",
    "        case_label_IG = case_label_IG.flatten()\n",
    "        PCC_check_flat_IG = PCC_check_flat_IG.flatten()\n",
    "        min_req_studs_IG = min_req_studs_IG.flatten()\n",
    "        min_studs_per_rib_IG = min_studs_per_rib_IG.flatten()\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        #----------------------Interior Infill-------------------------------\n",
    "        #--------------------------------------------------------------------\n",
    "\n",
    "        #----------------------Initial Values--------------------------------\n",
    "\n",
    "        SW_II = np.array(SW)[:, np.newaxis]  # Shape: (289, 1)\n",
    "        infill_Ix = np.array(Ix)[:, np.newaxis]\n",
    "        I_LB_II = np.array(I_LB_II)\n",
    "\n",
    "        # Trib width of Interior Infill\n",
    "        Trib_II = np.array(Girder_Span / (NumInfill + 1)).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Dead Load w/ Self Weight (psf)\n",
    "        DL_II = DL + (SW_II / Trib_II)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Dead Load (klf) = W_DL_II\n",
    "        W_DL_II = (DL_II * Trib_II) / 1000.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Live Load (klf) = W_LL_II\n",
    "        W_LL_II = np.array((LL * Trib_II) / 1000.0).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Total Load (klf) = W_TL_II\n",
    "        W_TL_II = ((DL_II + LL) * Trib_II) / 1000.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Construction Dead Load (klf) = W_Con_DL_II\n",
    "        W_Con_DL_II = (Final_Slab_SW * Trib_II + SW_II) / 1000.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Construction Live Load (klf) = W_Con_LL_II\n",
    "        W_Con_LL_II = np.array((20 * Trib_II) / 1000.0).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Composite Live Load (klf) = W_CLL_II\n",
    "        W_CLL_II = np.array(W_LL_II * 0.5).reshape(1,1) # Shape: ()\n",
    "\n",
    "        # Interior Infill Precomposite Factored Load (klf) = W_PC_II\n",
    "        W_PC_II_LC1 = 1.4 * W_Con_DL_II\n",
    "        W_PC_II_LC2 = 1.2 * W_Con_DL_II + 1.6 * W_Con_LL_II\n",
    "        W_PC_II = np.maximum(W_PC_II_LC1, W_PC_II_LC2)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Shear Dead Load (kips) = V_DL_II\n",
    "        V_DL_II = W_DL_II * Infill_Span / 2.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Shear Live Load (kips) = V_LL_II\n",
    "        V_LL_II = np.array(W_LL_II * Infill_Span / 2.0).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Shear Self Weight\n",
    "        V_SW_II = (SW_II / Trib_II) * Infill_Span / 2.0 * Trib_II  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Shear Factored Load (kips) = V_FL_II\n",
    "        V_II_LC1 = 1.4 * V_DL_II\n",
    "        V_II_LC2 = 1.2 * V_DL_II + 1.6 * V_LL_II\n",
    "        V_FL_II = np.maximum(V_II_LC1, V_II_LC2)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Construction Dead Load Shear (kips) = V_Con_DL_II\n",
    "        V_Con_DL_II = W_Con_DL_II * Infill_Span / 2.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Pre-Composite Factored Shear (kips) = V_PC_II\n",
    "        V_PC_II = W_PC_II * Infill_Span / 2.0  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Composite Live Load Shear (kips) = V_CLL_II\n",
    "        V_CLL_II = np.array(W_CLL_II * Infill_Span / 2.0).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Moment Dead Load (kips * ft ) = M_DL_II\n",
    "        M_DL_II = W_DL_II * Infill_Span ** 2 / 8  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Moment Live Load (kips * ft ) = M_LL_II\n",
    "        M_LL_II = np.array(W_LL_II * Infill_Span ** 2 / 8).reshape(1,) # Shape: ()\n",
    "\n",
    "        # Interior Infill Moment Factored Load (kips * ft ) = M_FL_II\n",
    "        M_II_LC1 = 1.4 * M_DL_II\n",
    "        M_II_LC2 = 1.2 * M_DL_II + 1.6 * M_LL_II\n",
    "        M_FL_II = np.maximum(M_II_LC1, M_II_LC2)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Pre-Composite Moment Factored Load (kips * ft ) = M_PC_II\n",
    "        M_PC_II = W_PC_II * Infill_Span ** 2 / 8  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Total Load Deflection DEF_TL_II\n",
    "        DEF_TL_II = (5*W_TL_II*(Infill_Span**4)*1728)/(384*Es*infill_Ix)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Live Load Deflection DEF_LL_II\n",
    "        DEF_LL_II = (5*W_LL_II*(Infill_Span**4)*1728)/(384*Es*infill_Ix) # Shape: ()\n",
    "\n",
    "        # Interior Infill Construction Deflection DEF_Con_II (no LL, no combos)\n",
    "        DEF_Con_II = (5*W_Con_DL_II*(Infill_Span**4)*1728)/(384*Es*infill_Ix)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Composite Live Load Deflection DEF_CLL_II\n",
    "        DEF_CLL_II = (5*W_CLL_II*(Infill_Span**4)*1728)/(384*Es*I_LB_II)# Shape: (289, 1) \n",
    "\n",
    "        # Interior Infill Check to make sure Camber is greater than 0.75\" and the Span is greater than 24'\n",
    "        camber_check = (np.around(0.8 * DEF_Con_II / 0.25) * 0.25 > 0.625) & (Infill_Span >= 24)  # Shape: (289, 1)\n",
    "\n",
    "        # Interior Infill Camber based on 0.8 * Construction Deflection, limited by l/360\n",
    "        camber_II = np.minimum(np.where(camber_check, np.around(0.8 * DEF_Con_II / 0.25) * 0.25, 0), 4) # Shape: (289, 1) Not cambering more than l/360\n",
    "\n",
    "        # Interior Infill Composite Dead Load Deflection\n",
    "        DEF_CDL_II = DEF_Con_II - camber_II\n",
    "\n",
    "        # Interior Infill Composite Total Load Deflection\n",
    "        DEF_CTL_II = DEF_CDL_II + DEF_CLL_II\n",
    "\n",
    "        #----------------------Filtering Sizes--------------------------------\n",
    "\n",
    "        # Pre-composite checks\n",
    "        PhiVnx_II = np.expand_dims(PhiVnx, axis = 1)\n",
    "        PhiMpx_II = np.expand_dims(PhiMpx, axis = 1)\n",
    "        pre_composite_V_check_II = V_PC_II <= PhiVnx_II\n",
    "        pre_composite_M_check_II = M_PC_II <= PhiMpx_II\n",
    "\n",
    "        # Composite checks\n",
    "        composite_V_check_II = V_FL_II <= PhiVnx_II\n",
    "        composite_M_check_II = M_FL_II <= Phi_Mn_II\n",
    "\n",
    "        # Deflecition checks\n",
    "        DL_DEF_check_II = np.array(DEF_CDL_II <= min(Infill_Span * 12 / 360, 1))\n",
    "        LL_DEF_check_II = np.array(DEF_CLL_II <= min(Infill_Span * 12 / 360, 1))\n",
    "        TL_DEF_check_II = np.array(DEF_CTL_II <= Infill_Span * 12 / 240)\n",
    "\n",
    "        # Economic Size Condition\n",
    "        Eco = np.expand_dims(np.array(Economic == 1), axis = 0)\n",
    "\n",
    "        # Combined Check\n",
    "        combined_check_II = (pre_composite_V_check_II &\n",
    "                             pre_composite_M_check_II & \n",
    "                             composite_V_check_II & \n",
    "                             composite_M_check_II & \n",
    "                             DL_DEF_check_II & \n",
    "                             LL_DEF_check_II & \n",
    "                             TL_DEF_check_II&\n",
    "                             PCC_check_II\n",
    "                            )\n",
    "\n",
    "        # Sorting\n",
    "        Groups_array = np.array(Groups)[:, np.newaxis]\n",
    "        Ingroup_array = np.array(Ingroup)[:, np.newaxis]\n",
    "\n",
    "        infill_sizes = np.expand_dims(shape_label, axis = 1).astype(str)\n",
    "        infill_depth = np.expand_dims(d, axis = 1)\n",
    "        infill_area = np.expand_dims(A, axis = 1)\n",
    "        infill_sw = np.expand_dims(SW, axis = 1)\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        #----------------------Interior Girder-------------------------------\n",
    "        #--------------------------------------------------------------------\n",
    "\n",
    "        #----------------------Initial Values--------------------------------\n",
    "\n",
    "        I_LB_IG = np.array(I_LB_IG).flatten()\n",
    "\n",
    "        #Self Weight of Interior Inifll    \n",
    "        SW_IG = np.expand_dims(np.array(SW), axis = (0)) # Shape: (1, 289)\n",
    "\n",
    "        #Trib width of Interior Girder\n",
    "        Trib_IG = Infill_Span # Shape: (1, )\n",
    "        Trib_II = Girder_Span / (NumInfill + 1) # Shape: (1, )\n",
    "\n",
    "        #Total SW of Infills on Interior Girders (kips * ft)\n",
    "        Total_SW_II = ((SW_II / 1000) * NumInfill * Trib_IG / Girder_Span) # Shape: (289, 1)\n",
    "\n",
    "        # Interior Girder Construction Dead Load (klf) = W_Con_DL_IG\n",
    "        W_Con_DL_IG = (Final_Slab_SW * Trib_IG + SW_IG) / 1000.0 + Total_SW_II # Shape: (289, 289)\n",
    "\n",
    "        # Interior Girder Construction Live Load (klf) = W_Con_LL_IG\n",
    "        W_Con_LL_IG = (20 * Trib_IG) / 1000.0 # Shape: (1, )\n",
    "\n",
    "        # Interior Girder Precomposite Factored Load (klf) = W_PC_IG\n",
    "        W_PC_IG_LC1 = 1.4 * W_Con_DL_IG\n",
    "        W_PC_IG_LC2 = 1.2 * W_Con_DL_IG + 1.6 * W_Con_LL_IG\n",
    "        W_PC_IG = np.maximum(W_PC_IG_LC1, W_PC_IG_LC2) # Shape: (289, 289)\n",
    "\n",
    "        #Interior Girder Shear Dead Load (kips) = V_DL_IG\n",
    "        V_DL_IG = ((SW_IG * Girder_Span / 1000) + 2 * V_DL_II * NumInfill) / 2 # Shape: (289, 289)\n",
    "\n",
    "        #Interior Girder Shear Dead Load (kips) = V_DL_IG\n",
    "        V_LL_IG = (2 * V_LL_II * NumInfill) / 2 # Shape: (1, )\n",
    "        \n",
    "        #Interior Girder Pre-Composite Factored Load (kips) = V_PC_IG\n",
    "        V_PC_IG = (2 * V_PC_II * NumInfill + SW_IG * Girder_Span / 1000) / 2 # Shape: (289, 289)\n",
    "\n",
    "        # Interior Girder Composite Live Load Shear (kips) = V_CLL_IG\n",
    "        V_CLL_IG = (2 * V_CLL_II * NumInfill) / 2 # Shape: (1, )\n",
    "\n",
    "        #Interior Girder Shear Factored Load (kips * ft ) = V_FL_IG\n",
    "        V_IG_LC1 = 1.4 * V_DL_IG\n",
    "        V_IG_LC2 = 1.2 * V_DL_IG + 1.6 * V_LL_IG\n",
    "        V_FL_IG = np.maximum(V_IG_LC1, V_IG_LC2) # Shape: (289, 289)\n",
    "\n",
    "        #Interior Girder Moment from SW (kips*ft) = M_SW_IG\n",
    "        M_SW_IG = np.array((SW_IG / 1000) * Girder_Span ** 2 / 8) # Shape: (1, 289)\n",
    "\n",
    "        #Interior Girder Moment Dead Load (kips*ft) = M_DL_IG\n",
    "        if NumInfill == 0:\n",
    "            M_DL_IG = M_SW_IG\n",
    "        if NumInfill == 1:\n",
    "            M_DL_IG = M_SW_IG + (2 * V_DL_II * Girder_Span / 4) # Shape: (289, 289)\n",
    "        if NumInfill == 2:\n",
    "            M_DL_IG = M_SW_IG + (2 * V_DL_II * Trib_II) # Shape: (289, 289)\n",
    "        if NumInfill == 3:\n",
    "            M_DL_IG = M_SW_IG + (2 * (2 * V_DL_II * Girder_Span / 4)) # Shape: (289, 289)\n",
    "        if NumInfill > 3:\n",
    "            M_DL_IG = M_SW_IG + ((DL / 1000) * Trib_IG) * Girder_Span ** 2 / 8 + (Total_SW_II * Girder_Span ** 2 / 8) # Shape: (289, 289)\n",
    "\n",
    "        #Interior Girder Moment Live Load (kips*ft) = M_DL_IG\n",
    "        if NumInfill == 0: \n",
    "            M_LL_IG = 0 \n",
    "        if NumInfill == 1:\n",
    "            M_LL_IG = (2 * V_LL_II * Girder_Span / 4) # Shape: (1, )\n",
    "        if NumInfill == 2:\n",
    "            M_LL_IG = (2 * V_LL_II * Trib_II) # Shape: (1, )\n",
    "        if NumInfill == 3:\n",
    "            M_LL_IG = (2 * (2 * V_LL_II * Girder_Span / 4)) # Shape: (1, )\n",
    "        if NumInfill > 3:\n",
    "            M_LL_IG = ((LL / 1000) * Trib_IG) * Girder_Span ** 2 / 8 # Shape: (1, )\n",
    "\n",
    "        #Interior Girder Moment Factored Load (kips * ft ) = M_FL_IG\n",
    "        M_IG_LC1 = 1.4 * M_DL_IG\n",
    "        M_IG_LC2 = 1.2 * M_DL_IG + 1.6 * M_LL_IG\n",
    "        M_FL_IG = np.maximum(M_IG_LC1, M_IG_LC2) # Shape: (289, 289)\n",
    "\n",
    "        # Interior Girder Pre-Composite Moment Factored Load (kips * ft ) = M_PC_IG\n",
    "        if NumInfill == 0:\n",
    "            M_PC_IG = M_SW_IG\n",
    "        if NumInfill == 1:\n",
    "            M_PC_IG = M_SW_IG + (2 * V_PC_II * Girder_Span / 4) # Shape: (289, 289)\n",
    "        if NumInfill == 2:\n",
    "            M_PC_IG = M_SW_IG + (2 * V_PC_II * Trib_II) # Shape: (289, 289)\n",
    "        if NumInfill == 3:\n",
    "            M_PC_IG = M_SW_IG + (2 * (2 * V_PC_II * Girder_Span / 4)) # Shape: (289, 289)\n",
    "        if NumInfill > 3:\n",
    "            M_PC_IG = W_PC_IG * Girder_Span ** 2 / 8 # Shape: (289, 289)\n",
    "\n",
    "        # Expand Ix to allow for NumPy vectorization\n",
    "        Ix_array = np.expand_dims(Ix, axis = 0)\n",
    "\n",
    "        #Interior Girder Deflection Self Weight (in) = DEF_SW_IG\n",
    "        DEF_SW_IG = (5 * (SW_IG / 1000) * (Girder_Span ** 4) * 1728) / (384 * Es * Ix_array) # Shape: (1, 289)\n",
    "        \n",
    "        #Interior Girder Live Load Deflection (in) = DEF_LL_IG\n",
    "        if NumInfill == 0:\n",
    "            DEF_LL_IG = 0\n",
    "        if NumInfill == 1:\n",
    "            DEF_LL_IG = ((2 * V_LL_II * (Girder_Span ** 3) * 1728) / (48 * Es * Ix))\n",
    "        if NumInfill == 2:\n",
    "            DEF_LL_IG = ((23 * 2 * V_LL_II * (Girder_Span ** 3) * 1728) / (648 * Es * Ix))\n",
    "        if NumInfill == 3:\n",
    "            DEF_LL_IG = ((22 * 2 * V_LL_II * (Girder_Span ** 3) * 1728) / (768 * 29000 * Ix)) + ((2 * V_LL_II * (Girder_Span ** 3) * 1728) / (48 * 29000 * Ix))\n",
    "        if NumInfill > 3:\n",
    "            DEF_LL_IG = (5 * ((LL / 1000) * Trib_IG) * (Girder_Span ** 4) * 1728) / (384 * Es * Ix)\n",
    "        \n",
    "        DEF_LL_IG = np.expand_dims(DEF_LL_IG, axis = 0) # Shape: (1, 289)\n",
    "\n",
    "        #Interior Girder Total Load Deflection (in) = DEF_TL_IG\n",
    "        if NumInfill == 0:\n",
    "            DEF_TL_IG = DEF_SW_IG\n",
    "        if NumInfill == 1:\n",
    "            DEF_TL_IG = DEF_SW_IG + DEF_LL_IG + ((2 * V_DL_II * (Girder_Span ** 3) * 1728) / (48 * Es * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill == 2:\n",
    "            DEF_TL_IG = DEF_SW_IG + DEF_LL_IG + ((23 * 2 * V_DL_II * (Girder_Span ** 3) * 1728) / (648 * Es * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill == 3:\n",
    "            DEF_TL_IG = DEF_SW_IG + DEF_LL_IG + ((22 * 2 * V_DL_II * (Girder_Span ** 3) * 1728) / (768 * 29000 * Ix_array)) + ((2 * V_DL_II * (Girder_Span ** 3) * 1728) / (48 * 29000 * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill > 3:\n",
    "            DEF_TL_IG = DEF_SW_IG + DEF_LL_IG + (5 * ((DL / 1000) * Trib_IG) * (Girder_Span ** 4) * 1728) / (384 * Es * Ix_array) # Shape: (289, 289)\n",
    "\n",
    "        # Interior Girder Construction Deflection (in) = DEF_Con_IG (no LL, no combos)\n",
    "        if NumInfill == 0:\n",
    "            DEF_Con_IG = DEF_SW_IG\n",
    "        if NumInfill == 1:\n",
    "            DEF_Con_IG = DEF_SW_IG + ((2 * V_Con_DL_II * (Girder_Span ** 3) * 1728) / (48 * Es * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill == 2:\n",
    "            DEF_Con_IG = DEF_SW_IG + ((23 * 2 * V_Con_DL_II * (Girder_Span ** 3) * 1728) / (648 * Es * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill == 3:\n",
    "            DEF_Con_IG = DEF_SW_IG + ((22 * 2 * V_Con_DL_II * (Girder_Span ** 3) * 1728) / (768 * 29000 * Ix_array)) + ((2 * V_Con_DL_II * (Girder_Span ** 3) * 1728) / (48 * 29000 * Ix_array)) # Shape: (289, 289)\n",
    "        if NumInfill > 3:\n",
    "            DEF_Con_IG = (5 * W_Con_DL_IG * (Girder_Span ** 4) * 1728) / (384 * Es * Ix_array) # Shape: (289, 289)     \n",
    "\n",
    "        # Interior Girder Composite Live Load Deflection (in) = DEF_CLL_IG\n",
    "        if NumInfill == 0:\n",
    "            DEF_CLL_IG = 0\n",
    "        if NumInfill == 1:\n",
    "            DEF_CLL_IG = ((2 * V_CLL_II * (Girder_Span ** 3) * 1728) / (48 * Es * I_LB_IG))\n",
    "        if NumInfill == 2:\n",
    "            DEF_CLL_IG = ((23 * 2 * V_CLL_II * (Girder_Span ** 3) * 1728) / (648 * Es * I_LB_IG))\n",
    "        if NumInfill == 3:\n",
    "            DEF_CLL_IG = ((22 * 2 * V_CLL_II * (Girder_Span ** 3) * 1728) / (768 * 29000 * I_LB_IG)) + ((2 * V_CLL_II * (Girder_Span ** 3) * 1728) / (48 * 29000 * I_LB_IG))\n",
    "        if NumInfill > 3:\n",
    "            DEF_CLL_IG = (5 * ((0.5 * LL / 1000) * Trib_IG) * (Girder_Span ** 4) * 1728) / (384 * Es * I_LB_IG)\n",
    "        \n",
    "        DEF_CLL_IG = np.expand_dims(DEF_CLL_IG, axis = 0) # Shape: (1, 289)\n",
    "\n",
    "        # Interior Girder Check to make sure Camber is greater than 0.75\" and the Span is greater than 24'\n",
    "        camber_check_IG = (np.around(0.8 * DEF_Con_IG / 0.25) * 0.25 > 0.625) & (Girder_Span >= 24)\n",
    "\n",
    "        # Interior Girder Camber based on 0.8 * Construction Deflection, limited by l/360\n",
    "        camber_IG = np.minimum(np.where(camber_check_IG, np.round(0.8 * DEF_Con_IG / 0.25) * 0.25, 0), 4) # Shape: (289, 289)\n",
    "\n",
    "        # Interior Infill Composite Dead Load Deflection (in) = DEF_CDL_IG\n",
    "        DEF_CDL_IG = DEF_Con_IG - camber_IG # Shape: (289, 289)\n",
    "\n",
    "        # Interior Girder Composite Total Load Deflection\n",
    "        DEF_CTL_IG = DEF_CDL_IG + DEF_CLL_IG\n",
    "\n",
    "        #Cb Values (Table 3-1)\n",
    "        if NumInfill == 0:\n",
    "            Cb = 1.14\n",
    "        if NumInfill == 1:\n",
    "            Cb = 1.67\n",
    "        if NumInfill == 2:\n",
    "            Cb = 1\n",
    "        if NumInfill == 3:\n",
    "            Cb = 1.11\n",
    "        if NumInfill > 3:\n",
    "            Cb = 1\n",
    "    \n",
    "        #----------------------Filtering Sizes--------------------------------\n",
    "\n",
    "        #Flexure Check (Lb<=Lp)\n",
    "        Lb = Girder_Span / (NumInfill + 1)\n",
    "        Compact = Lb <= Lp\n",
    "        Compact_PhiMn = np.where(Compact, PhiMpx, np.nan)\n",
    "\n",
    "        #Flexure Check (Lp < Lb <=Lr)\n",
    "        Noncompact1 = Lp < Lb\n",
    "        Noncompact2 = Lb <= Lr\n",
    "        Noncompact_LTB = Cb*(PhiMpx-PhiBF*(Lb-Lp))\n",
    "        Noncompact_PhiMn = np.where(Noncompact1 & Noncompact2, np.minimum(Noncompact_LTB, PhiMpx), np.nan)\n",
    "\n",
    "        #Flexure Check (Lr < Lb)\n",
    "        Slender = Lb > Lr\n",
    "        Fcr = ((Cb*(np.pi)**2*Es)/(Lb*12/rts)**2)*np.sqrt(1+0.078*(Jc/(Sx*ho))*(Lb*12/rts)**2)\n",
    "        Slender_LTB = 0.9*((Fcr*Sx)/12)\n",
    "        Slender_PhiMn = np.where(Slender, np.minimum(Slender_LTB, PhiMpx), np.nan)\n",
    "\n",
    "        #Pre-composite Flexure Check\n",
    "        PhiMn_PC_IG = np.where(~np.isnan(Compact_PhiMn), Compact_PhiMn, np.where(~np.isnan(Noncompact_PhiMn), Noncompact_PhiMn, Slender_PhiMn))\n",
    "\n",
    "        # Pre-composite checks\n",
    "        PhiVnx_IG = np.expand_dims(PhiVnx, axis = 0)\n",
    "        pre_composite_V_check_IG = V_PC_IG <= PhiVnx_IG #\n",
    "        pre_composite_M_check_IG = M_PC_IG <= PhiMn_PC_IG\n",
    "\n",
    "        #Composite checks\n",
    "        composite_V_check_IG = V_FL_IG <= PhiVnx_IG\n",
    "        composite_M_check_IG = M_FL_IG <= Phi_Mn_IG\n",
    "\n",
    "        # Deflecition checks\n",
    "        DL_DEF_check_IG = DEF_CDL_IG <= min(Girder_Span * 12 / 360, 1)\n",
    "        LL_DEF_check_IG = DEF_CLL_IG <= min(Girder_Span * 12 / 360, 1)\n",
    "        TL_DEF_check_IG = DEF_CTL_IG <= Girder_Span * 12 / 240\n",
    "\n",
    "        # Infill fitting inside girders\n",
    "        infill_d = np.expand_dims(d, axis = 1)\n",
    "        girder_T = np.expand_dims(T, axis = 0)\n",
    "        depth_check = girder_T >= infill_d\n",
    "\n",
    "        # Combined Check\n",
    "        combined_check_IG = (pre_composite_V_check_IG & \n",
    "                             pre_composite_M_check_IG & \n",
    "                             composite_V_check_IG &\n",
    "                             composite_M_check_IG &\n",
    "                             DL_DEF_check_IG & \n",
    "                             LL_DEF_check_IG &\n",
    "                             TL_DEF_check_IG &\n",
    "                             depth_check &\n",
    "                             Eco &\n",
    "                             PCC_check_flat_IG\n",
    "                             )\n",
    "        combined_check = combined_check_II & combined_check_IG\n",
    "        \n",
    "        # Create a mask that selects the most economic infill of each grouping\n",
    "        groups_filtered = pd.DataFrame(np.where(combined_check, Groups_array, np.nan))\n",
    "        ingroup_filtered = np.where(combined_check, Ingroup_array, np.nan)\n",
    "    \n",
    "        mask = pd.DataFrame(False, index=groups_filtered.index, columns=groups_filtered.columns)\n",
    "\n",
    "        for column in groups_filtered.columns:\n",
    "            # Mark the first occurrence of each unique value\n",
    "            first_occurrences = groups_filtered[column].duplicated(keep='first') == False\n",
    "            # Set the corresponding indices in the mask to True\n",
    "            mask[column][first_occurrences] = True\n",
    "\n",
    "        final_check = combined_check & mask\n",
    "\n",
    "\n",
    "        girder_sizes = np.expand_dims(shape_label, axis = 0).astype(str)\n",
    "        girder_depth = np.expand_dims(d, axis = 0)\n",
    "        girder_area = np.expand_dims(A, axis = 0)\n",
    "        girder_Ix = np.expand_dims(Ix, axis = 0)\n",
    "        girder_sw = np.expand_dims(SW, axis = 0)\n",
    "    \n",
    "        #--------------------------------------------------------------------\n",
    "        #----------------------Vibration Calc--------------------------------\n",
    "        #--------------------------------------------------------------------\n",
    "\n",
    "        dead_load = 4   #for vibations\n",
    "        damping_ratio = DR\n",
    "\n",
    "        effective_conc_depth = selected_deck_topping_thickness + Additional_Topping\n",
    "\n",
    "        #Deck Properties\n",
    "        Ec = conc_density ** 1.5 * ms.sqrt(f_prime_c) #ksi\n",
    "\n",
    "        #n Calc\n",
    "        n = Es / (1.35 * Ec)\n",
    "\n",
    "        #Effective Concrete Slab Width for Infills\n",
    "        effective_conc_width = min(0.4 * Infill_Span * 12, infill_spacing * 12) #in\n",
    "\n",
    "        #Transformed Concrete Slab Width for Infills\n",
    "        transformed_conc_width = effective_conc_width / n #in\n",
    "\n",
    "        #Transformed Concrete Slab Area for Infills\n",
    "        transformed_conc_area = effective_conc_depth * transformed_conc_width #in^2\n",
    "\n",
    "        #Transformed Moment of Inertia for Infills\n",
    "        y_bar_infill = (transformed_conc_area * (infill_depth / 2 + Deck_Type + effective_conc_depth / 2)) / (transformed_conc_area + infill_area)\n",
    "\n",
    "        Ij = (transformed_conc_width * effective_conc_depth ** 3 / 12 + transformed_conc_area * \n",
    "              (infill_depth / 2 + Deck_Type + effective_conc_depth / 2 - y_bar_infill) ** 2 + infill_Ix + infill_area * y_bar_infill ** 2)\n",
    "\n",
    "        #Infill uniformly distributed load\n",
    "        wj = infill_spacing*(live_load_vibrations + Final_Slab_SW + dead_load) + infill_sw\n",
    "\n",
    "        #Infill deflection using Transformed Moment of Intertia\n",
    "        DEF_j = (5 * wj * Infill_Span ** 4 * 1728) / (384 * (Es * 1000) * Ij)\n",
    "\n",
    "        #Infill fundamental frequency\n",
    "        fj = 0.18 * np.sqrt(386 / DEF_j)\n",
    "\n",
    "        #transformed slab moment of inertia per unit width\n",
    "        de = effective_conc_depth + Deck_Type / 2\n",
    "        Ds = (12 * de ** 3) / (12 * n)\n",
    "\n",
    "        #The transformed moment of inertia per unit width for Infills\n",
    "        Dj = Ij / infill_spacing\n",
    "\n",
    "        #The effective beam panel width of Infills\n",
    "        Cj = 2.0\n",
    "        Bj = Cj * (Ds / Dj) ** 0.25 * Infill_Span\n",
    "\n",
    "        #is Bj <= (2/3) * floor width\n",
    "        floor_width = 200 #ft\n",
    "        floor_width_check = (2/3) * floor_width\n",
    "        Bj_check = Bj <= floor_width_check\n",
    "\n",
    "        #The weight of the beam panel (x1.5 because I am assuimng girder is shear connected)\n",
    "        Wj = 1.5 * (wj / infill_spacing) * Bj * Infill_Span\n",
    "\n",
    "        #Girder Transformed Moment of Inertia\n",
    "        #The effective concrete slab width\n",
    "        effective_conc_width_girder = min(0.2 * Girder_Span, 0.5 * Infill_Span) * 12 + min(0.2 * Girder_Span, 0.5 * Infill_Span) *12 #in\n",
    "\n",
    "        #Transformed Concrete Slab Width for Girders\n",
    "        transformed_conc_width_girder = effective_conc_width_girder / n #in\n",
    "\n",
    "        #Transformed Concrete Slab Width of Deck\n",
    "        transformed_conc_width_deck = effective_conc_width_girder / 2 / n #in\n",
    "\n",
    "        #Transformed Concrete Slab Area for Girders\n",
    "        transformed_conc_area_girder = effective_conc_depth * transformed_conc_width_girder #in^2\n",
    "\n",
    "        #Transformed Concrete Slab Area of Deck\n",
    "        transformed_conc_area_deck = Deck_Type * transformed_conc_width_deck #in^2\n",
    "\n",
    "        # Transformed Moment of Inertia for Girders\n",
    "        y_bar_girder = (transformed_conc_area_girder * (girder_depth / 2 + Deck_Type + effective_conc_depth / 2) + transformed_conc_area_deck * \n",
    "                        (girder_depth / 2 + Deck_Type / 2)) / (transformed_conc_area_girder + transformed_conc_area_deck + girder_area)\n",
    "\n",
    "        Ig = (transformed_conc_width_girder * effective_conc_depth ** 3 / 12 + transformed_conc_area_girder * (girder_depth / 2 + Deck_Type + effective_conc_depth / 2 - y_bar_girder) ** 2 \n",
    "              + transformed_conc_width_deck * Deck_Type ** 3 / 12 + transformed_conc_area_deck * (girder_depth / 2 + Deck_Type / 2 - y_bar_girder) ** 2 + girder_Ix + girder_area * y_bar_girder ** 2)\n",
    "        \n",
    "        #Girder uniformly distributed load\n",
    "        wg = Infill_Span * (wj / infill_spacing) + girder_sw #plf\n",
    "\n",
    "        #Girder deflection using Transformed Moment of Intertia\n",
    "        DEF_g = (5 * wg * Girder_Span ** 4 *1728) / (384 * 29 * 10 ** 6 * Ig) #in\n",
    "\n",
    "        #Infill fundamental frequency\n",
    "        fg = 0.18 * np.sqrt(386 / DEF_g) #Hz\n",
    "\n",
    "        #The transformed moment of inertia per unit width for Girders\n",
    "        Dg = Ig / Infill_Span #in^4 / ft\n",
    "\n",
    "        #The effective beam panel width of Girders\n",
    "        Cg = 1.8 #Assuming infills are connected to Girder Web\n",
    "        Bg = Cg * (Dj / Dg) ** 0.25 * Girder_Span #ft\n",
    "\n",
    "        #is Bg <= (2/3) * floor length\n",
    "        floor_length = 200 #ft\n",
    "        floor_length_check = (2/3) * floor_length\n",
    "        Bg_check = Bg <= floor_length_check\n",
    "\n",
    "        #The weight of the girder panel\n",
    "        Wg = (wg / Infill_Span) * Bg * Girder_Span #lbs\n",
    "\n",
    "        #Floor Fundamental Frequency\n",
    "        fn = 0.18 * np.sqrt(386 / (DEF_j + DEF_g)) #Hz\n",
    "\n",
    "        #Girder Deflection Reduction\n",
    "        girder_deflection_reduction = Girder_Span < Bj\n",
    "        DEF_g_reduced = np.where(girder_deflection_reduction, np.maximum(((Girder_Span / Bj) * DEF_g), 0.5 * DEF_g), DEF_g)\n",
    "\n",
    "        #equivalent panel mode panel weigh\n",
    "        W = DEF_j / (DEF_j + DEF_g_reduced) * Wj + DEF_g_reduced / (DEF_j + DEF_g_reduced) * Wg\n",
    "\n",
    "        #ratio of the peak floor acceleration to the acceleration of gravity\n",
    "        ap_over_g = (65 * ms.e ** (-0.35 * fn)) / (damping_ratio * W)\n",
    "\n",
    "        #peak acceleration\n",
    "        peak_acceleration = ap_over_g * 100\n",
    "        vibration_check = peak_acceleration <= tolerance_limit\n",
    "\n",
    "        #--------------------------------------------------------------------\n",
    "        #---------------------------EC Calcs---------------------------------\n",
    "        #--------------------------------------------------------------------\n",
    "\n",
    "        #Bay Area\n",
    "        bay_area = Infill_Span * Girder_Span\n",
    "\n",
    "        #Steel w_shape Weight\n",
    "        steel_w_infill = infill_sw * Infill_Span * (NumInfill + 2)\n",
    "        steel_w_girder = girder_sw * Girder_Span * 2\n",
    "        steel_w = steel_w_infill + steel_w_girder #lbs\n",
    "\n",
    "        #Steel deck weight\n",
    "        steel_deck_w = selected_deck_SW * bay_area\n",
    "\n",
    "        #3/4\" stud weight\n",
    "        if Deck_Type == 1.5:\n",
    "            per_stud_w = 0.374 #lbs per stud\n",
    "        elif Deck_Type == 2:\n",
    "            per_stud_w = 0.437\n",
    "        elif Deck_Type == 3:\n",
    "            per_stud_w = 0.562\n",
    "        \n",
    "        studs_w_infill = per_stud_w * min_req_studs_II * (NumInfill + 2)\n",
    "        studs_w_girder = per_stud_w * min_req_studs_IG * 2\n",
    "        studs_w = studs_w_infill + studs_w_girder\n",
    "        \n",
    "        #Conc Weight\n",
    "        conc_w = (selected_deck_topping_thickness + Conc_Depth_in_Flute + Additional_Topping) / 12 * conc_density * bay_area #lbs\n",
    "\n",
    "        #Embodied Carbon\n",
    "        EC = steel_w * 1.22 + steel_deck_w * 2.32 + studs_w * 1.27 + conc_w * Conc_ECV #lbCO2e\n",
    "\n",
    "        #Embodied Carbon Scaled\n",
    "        EC_scaled = EC / bay_area #lbCO2e/ft^2\n",
    "\n",
    "        #Dictionary of variables to be used outside defenition\n",
    "        results = {\n",
    "            'Selected Deck': selected_deck,\n",
    "            'SW_II': SW_II,\n",
    "            'SW_IG': SW_IG,\n",
    "            'DR': np.array(damping_ratio),\n",
    "            'Peak Acceleration': peak_acceleration,\n",
    "            'Embodied Carbon Scaled': EC_scaled,\n",
    "            'Infill Sizes': infill_sizes,\n",
    "            'Girder Sizes': girder_sizes,\n",
    "            'Groups Array': Groups_array,\n",
    "            'Groups': Groups,\n",
    "            'Final Check': final_check,\n",
    "            'W_DL_II': W_DL_II,\n",
    "            'W_LL_II': W_LL_II,\n",
    "            'V_FL_II': V_FL_II,\n",
    "            'V_FL_IG': V_FL_IG,\n",
    "            'M_FL_II': M_FL_II,\n",
    "            'M_FL_IG': M_FL_IG,\n",
    "            'M_PC_II': M_PC_II,\n",
    "            'M_PC_IG': M_PC_IG,\n",
    "            'DEF_CLL_II': DEF_CLL_II,\n",
    "            'DEF_CLL_IG': DEF_CLL_IG,\n",
    "            'DEF_CDL_II': DEF_CDL_II,\n",
    "            'DEF_CDL_IG': DEF_CDL_IG,\n",
    "            'DEF_Con_II': DEF_Con_II,\n",
    "            'DEF_Con_IG': DEF_Con_IG,\n",
    "            'DEF_CTL_II': DEF_CTL_II,\n",
    "            'DEF_CTL_IG': DEF_CTL_IG,\n",
    "            'Phi_Mn_II': Phi_Mn_II,\n",
    "            'Phi_Mn_IG': Phi_Mn_IG,\n",
    "            'PhiVnx_II': PhiVnx_II,\n",
    "            'PhiVnx_IG': PhiVnx_IG,            \n",
    "            'PhiMpx_II': PhiMpx_II,   \n",
    "            'PhiMn_PC_IG': PhiMn_PC_IG,\n",
    "            'Y1_II': Y1_II,\n",
    "            'Y1_IG': Y1_IG,\n",
    "            'Y2_II': Y2_II,\n",
    "            'Y2_IG': Y2_IG,\n",
    "            'camber_II': camber_II,\n",
    "            'camber_IG': camber_IG,\n",
    "            'I_LB_II': I_LB_II,\n",
    "            'I_LB_IG': I_LB_IG,\n",
    "            'Case Label II': case_label_II,\n",
    "            'Case Label IG': case_label_IG,\n",
    "            'effective': effective_conc_depth,\n",
    "            'Total Topping': Final_Slab_Thickness,\n",
    "            'Fundamental Frequency': fn,\n",
    "            'Studs II': min_req_studs_II,\n",
    "            'Studs IG': min_req_studs_IG,\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    #----------------------Dataframe Creation--------------------------------\n",
    "    #------------------------------------------------------------------------\n",
    "    \n",
    "    # Base calculation\n",
    "    base_results = mitigation_method(0)\n",
    "\n",
    "    if base_results == None:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        combined_matrix = np.vectorize(lambda x, y: f\"Infill: {x}, Girder: {y}\")(base_results['Infill Sizes'], base_results['Girder Sizes'])\n",
    "\n",
    "    #Transforms 1d array to apply to infill values\n",
    "    def expand_infill(value):\n",
    "        return np.repeat(np.expand_dims(value, axis=1), repeats=273, axis=1)\n",
    "    \n",
    "    #Transforms 1d array to apply to girder values\n",
    "    def expand_girder(value):\n",
    "        value_reshape = value.reshape(1, 273)\n",
    "        return np.repeat(value_reshape, 273, axis=0)\n",
    "\n",
    "    def map_to_matrices(range_traversal_df, target_matrices_dict):\n",
    "        \"\"\"\n",
    "        Map column and row indices from range_traversal_df to multiple target matrices.\n",
    "\n",
    "        Parameters:\n",
    "        range_traversal_df (pd.DataFrame): DataFrame containing ColIdx, RowIdx, ColumnName, and Value.\n",
    "        target_matrices_dict (dict): Dictionary where keys are matrix names and values are target matrices (numpy arrays).\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: DataFrame with the mapped values from all target matrices as new columns.\n",
    "        \"\"\"\n",
    "        mapped_results = range_traversal_df.copy()\n",
    "\n",
    "        # Iterate over each target matrix in the dictionary\n",
    "        for matrix_name, target_matrix in target_matrices_dict.items():\n",
    "            mapped_values = []\n",
    "\n",
    "            # Map values from the target matrix using the column and row indices\n",
    "            for _, row in range_traversal_df.iterrows():\n",
    "                col_idx = row[\"ColIdx\"]\n",
    "                row_idx = row[\"RowIdx\"]\n",
    "\n",
    "                # Retrieve the value from the matrix\n",
    "                try:\n",
    "                    mapped_value = target_matrix[row_idx, col_idx]\n",
    "                except IndexError:\n",
    "                    mapped_value = np.nan  # Handle out-of-bounds indices gracefully\n",
    "\n",
    "                # Add the mapped value to the list\n",
    "                mapped_values.append(mapped_value)\n",
    "\n",
    "            # Add the mapped values as a new column to the DataFrame\n",
    "            mapped_results[f\"{matrix_name}\"] = mapped_values\n",
    "\n",
    "        return mapped_results\n",
    "    \n",
    "    #Dictonary of all values returned in final upsizing dataframe\n",
    "    target_base_matrices = {\n",
    "        \"Damping Ratio\": np.full((273, 273),base_results['DR']),\n",
    "        \"Additional Topping\": np.zeros_like(base_results['Peak Acceleration']),\n",
    "        \"Peak Acceleration\": base_results['Peak Acceleration'],\n",
    "        \"Embodied Carbon Scaled\": base_results['Embodied Carbon Scaled'],\n",
    "        \"Selected Deck\": np.array(base_results['Selected Deck']).flatten(),\n",
    "        \"Combined Sizes\": combined_matrix,\n",
    "        \"Infill Sizes\": expand_infill(base_results['Infill Sizes'].flatten()),\n",
    "        \"Infill Studs\": expand_infill(base_results['Studs II']),\n",
    "        \"Infill Shear\": expand_infill(base_results['V_FL_II']),\n",
    "        \"Infill Shear Capacity\": expand_infill(base_results['PhiVnx_II']),\n",
    "        \"Infill PC Moment\": expand_infill(base_results['M_PC_II']),       \n",
    "        \"Infill PC Moment Capcity\": expand_infill(base_results['PhiMpx_II']), \n",
    "        \"Infill Moment\": expand_infill(base_results['M_FL_II']),\n",
    "        \"Infill Moment Capcity\": expand_infill(base_results['Phi_Mn_II']),\n",
    "        \"Y1_II\": expand_infill(base_results['Y1_II']),\n",
    "        \"Y2_II\": expand_infill(base_results['Y2_II']),\n",
    "        \"Infill Contruction Load Deflection\": expand_infill(base_results['DEF_Con_II']),\n",
    "        \"Infill Camber\": expand_infill(base_results['camber_II']),\n",
    "        \"Infill Composite Dead Load Deflection\": expand_infill(base_results['DEF_CDL_II']),\n",
    "        \"Infill I_LB\": expand_infill(base_results['I_LB_II']),\n",
    "        \"Infill Composite Live Load Deflection\": expand_infill(base_results['DEF_CLL_II']),\n",
    "        \"Infill Composite Total Load Deflection\": expand_infill(base_results['DEF_CTL_II']),\n",
    "        \"Infill Case Label\": expand_infill(base_results['Case Label II']),\n",
    "        \"Girder Sizes\": expand_girder(base_results['Girder Sizes'].flatten()),\n",
    "        \"Girder Studs\": expand_girder(base_results['Studs IG']),\n",
    "        \"Girder Shear\": base_results['V_FL_IG'],\n",
    "        \"Girder Shear Capacity\": expand_girder(base_results['PhiVnx_IG']),\n",
    "        \"Girder PC Moment\": base_results['M_PC_IG'],       \n",
    "        \"Girder PC Moment Capcity\": expand_girder(base_results['PhiMn_PC_IG']), \n",
    "        \"Girder Moment\": base_results['M_FL_IG'],\n",
    "        \"Girder Moment Capcity\": expand_girder(base_results['Phi_Mn_IG']),\n",
    "        \"Y1_IG\": expand_girder(base_results['Y1_IG']),\n",
    "        \"Y2_IG\": expand_girder(base_results['Y2_IG']),\n",
    "        \"Girder Contruction Load Deflection\": base_results['DEF_Con_IG'],\n",
    "        \"Girder Camber\": base_results['camber_IG'],\n",
    "        \"Girder Composite Dead Load Deflection\": base_results['DEF_CDL_IG'],\n",
    "        \"Girder I_LB\": np.tile(np.array(base_results['I_LB_IG']).reshape(1, -1), (273, 1)),\n",
    "        \"Girder Composite Live Load Deflection\": expand_girder(base_results['DEF_CLL_IG']),\n",
    "        \"Girder Composite Total Load Deflection\": base_results['DEF_CTL_IG'],\n",
    "        \"Girder Case Label\": expand_girder(base_results['Case Label IG']),\n",
    "        \"Total Topping\": base_results['Total Topping'],\n",
    "        \"Fundamental Frequency\": base_results['Fundamental Frequency']\n",
    "\n",
    "    }\n",
    "\n",
    "    def initial_values(base_results):\n",
    "        \"\"\"\n",
    "        Designs the initial design based on structural limit states and calculates EC and peak acceleration\n",
    "\n",
    "        Parameters:\n",
    "        base_results (dict): Dictionary of all initial \n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: DataFrame with the initial mapped values from all target matrices as new columns.\n",
    "        \"\"\"\n",
    "\n",
    "        #DataFrame of the EC Values\n",
    "        EC_dataframe = pd.DataFrame(np.where(base_results['Final Check'], base_results['Embodied Carbon Scaled'], np.nan),\n",
    "                                     index=base_results['Infill Sizes'].flatten(),\n",
    "                                       columns=base_results['Girder Sizes'].flatten())\n",
    "\n",
    "        # Check if EC_dataframe contains only NaN values\n",
    "        if EC_dataframe.isnull().all().all():\n",
    "            print(f\"No valid sizes found for {percent_comp}% composite action.\")\n",
    "            dummy_df = pd.DataFrame({\n",
    "                'ColIdx': [0],\n",
    "                'RowIdx': [0]\n",
    "            })\n",
    "            mapped_results = map_to_matrices(dummy_df, target_base_matrices)\n",
    "            # Set all values to 0\n",
    "            for col in mapped_results.columns:\n",
    "                mapped_results[col] = 0\n",
    "            return mapped_results\n",
    "\n",
    "        # Find the minimum value and its location\n",
    "        min_location = EC_dataframe.stack().idxmin()\n",
    "\n",
    "        # Convert row and column labels to integer indices\n",
    "        row_index = EC_dataframe.index.get_loc(min_location[0])  # Convert row label to index\n",
    "        col_index = EC_dataframe.columns.get_loc(min_location[1])  # Convert column label to index\n",
    "\n",
    "        # Or alternatively, using lists:\n",
    "        initial_df = pd.DataFrame({\n",
    "            'ColIdx': [col_index],\n",
    "            'RowIdx': [row_index]\n",
    "        })\n",
    "\n",
    "\n",
    "        # Map the matrices using the updated function\n",
    "        mapped_results_df = map_to_matrices(initial_df, target_base_matrices)\n",
    "\n",
    "        return mapped_results_df\n",
    "    \n",
    "    #Call Initial Sizing DF\n",
    "    initial_values_df = initial_values(base_results)\n",
    "\n",
    "    #-----------------------Infill Upsizing----------------------------------\n",
    "\n",
    "    def infill_upsizing(base_results):\n",
    "        \"\"\"\n",
    "        For intial designs expected to exceed the peak acceleration tolerance limit, infills are upsized until the limit is met\n",
    "\n",
    "        Parameters:\n",
    "        base_results (dict): Dictionary of all initial values used in design\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: DataFrame with the all infill upsizings mapped to values from all target matrices as new columns.\n",
    "        \"\"\"\n",
    "\n",
    "        #DataFrame of the EC Values\n",
    "        EC_dataframe = pd.DataFrame(np.where(base_results['Final Check'], base_results['Embodied Carbon Scaled'], np.nan),\n",
    "                                     index=base_results['Infill Sizes'].flatten(),\n",
    "                                       columns=base_results['Girder Sizes'].flatten())\n",
    "\n",
    "        # Check if EC_dataframe contains only NaN values\n",
    "        if EC_dataframe.isnull().all().all():\n",
    "            dummy_df = pd.DataFrame(0, index=range(1), columns=list(target_base_matrices.keys()) + ['# of Upsizes'])\n",
    "            return dummy_df\n",
    "        \n",
    "        # Find the minimum value and its location\n",
    "        min_location = EC_dataframe.stack().idxmin()\n",
    "\n",
    "        # Convert row and column labels to integer indices\n",
    "        row_index = EC_dataframe.index.get_loc(min_location[0])  # Convert row label to index\n",
    "        col_index = EC_dataframe.columns.get_loc(min_location[1])  # Convert column label to index\n",
    "\n",
    "        # Create a DataFrame of the PhiMn Grouping\n",
    "        Grouping_dataframe = base_results['Groups Array']\n",
    "        \n",
    "        #DataFrame of the PhiMn Grouping, with final check masking\n",
    "        Grouping_df = pd.DataFrame(\n",
    "            np.where(base_results['Final Check'], Grouping_dataframe, np.nan),\n",
    "            index=base_results['Infill Sizes'].flatten(),\n",
    "            columns=base_results['Girder Sizes'].flatten()\n",
    "        )\n",
    "\n",
    "        #Removes all columns to the right of the lowest observed EC value in matrix to begin Infill Upsizing\n",
    "        Grouping_df= Grouping_df.iloc[:, :col_index+1]\n",
    "\n",
    "        # Compute max and min values\n",
    "        max_values = Grouping_df.max(skipna=True)\n",
    "        min_values = Grouping_df.min(skipna=True)\n",
    "\n",
    "        # Convert dictionary to list of tuples for processing\n",
    "        min_values_list = list(min_values.items())\n",
    "\n",
    "        # Initialize variables for filtering\n",
    "        filtered_indices = []\n",
    "        current_min = float('inf')  # Start with infinity to find the minimum\n",
    "\n",
    "        # Traverse the list from bottom to top\n",
    "        for index, item in enumerate(reversed(min_values_list)):\n",
    "            column_name, value = item\n",
    "            if value < current_min:\n",
    "                # Only add the item if it's less than the current minimum seen\n",
    "                current_min = value\n",
    "                # Find the row index of this value in the respective column\n",
    "                row_index = Grouping_df[column_name].tolist().index(value)\n",
    "                # Add the column index, row index, column name, and value to the filtered_indices\n",
    "                column_index = list(Grouping_df.columns).index(column_name)\n",
    "                filtered_indices.append((len(min_values_list) - 1 - index, column_index, row_index, column_name, value))\n",
    "\n",
    "        # Reverse the filtered_indices to restore the original order\n",
    "        filtered_indices.reverse()\n",
    "\n",
    "        # Handle the bottom column index\n",
    "        bottom_column_index = filtered_indices[-1][0]\n",
    "        max_value_bottom_column = max_values[bottom_column_index]\n",
    "\n",
    "        # Create a DataFrame for sorting results\n",
    "        sorting_df = pd.DataFrame(filtered_indices, columns=[\"Idx\", \"ColIdx\", \"RowIdx\", \"ColumnName\", \"Value\"])\n",
    "\n",
    "\n",
    "        # Add the bottom column max value to the sorted group\n",
    "        sorted_groups = list(sorting_df[\"Value\"]) + [max_value_bottom_column]\n",
    "\n",
    "        # Initialize an empty list to store ranges\n",
    "        ranges = []\n",
    "\n",
    "        # Loop through the sorted_groups to create ranges\n",
    "        for i in range(len(sorted_groups) - 1):\n",
    "            start = int(sorted_groups[i])  # Start value of the range\n",
    "            end = int(sorted_groups[i + 1])  # End value of the range\n",
    "            ranges.append(list(range(start, end + 1)))  # Add range to the list\n",
    "\n",
    "        sorting_df[\"Ranges\"] = ranges\n",
    "\n",
    "        # Now integrate the traverse_ranges function to process ranges\n",
    "        def traverse_ranges(dataframe, sorting_df):\n",
    "            \"\"\"\n",
    "            Traverse the dataframe for all the range values for each column specified in sorting_df.\n",
    "            \"\"\"\n",
    "            result = []\n",
    "            \n",
    "            # Loop through each row in sorting_df to process its ranges\n",
    "            for _, row in sorting_df.iterrows():\n",
    "                col_name = row[\"ColumnName\"]\n",
    "                col_idx = row[\"ColIdx\"]\n",
    "                col_ranges = row[\"Ranges\"]\n",
    "                \n",
    "                # Traverse each value in the range and find its index in the column\n",
    "                for value in col_ranges:\n",
    "                    if value in dataframe[col_name].values:\n",
    "                        row_idx = dataframe[col_name].tolist().index(value)\n",
    "                        result.append((col_idx, row_idx, col_name, value))\n",
    "                    else:\n",
    "                        # If value isn't present, skip it\n",
    "                        continue\n",
    "            \n",
    "            # Convert the result into a DataFrame for easier viewing and processing\n",
    "            range_traversal_df = pd.DataFrame(result, columns=[\"ColIdx\", \"RowIdx\", \"ColumnName\", \"Value\"])\n",
    "            return range_traversal_df\n",
    "\n",
    "        # Call the traverse_ranges function to process ranges\n",
    "        range_traversal_df = traverse_ranges(Grouping_df, sorting_df)\n",
    "\n",
    "        # Map the matrices using the updated function\n",
    "        mapped_results_df = map_to_matrices(range_traversal_df, target_base_matrices)\n",
    "    \n",
    "        # Reverse the rows of the DataFrame\n",
    "        mapped_results_df = mapped_results_df[::-1].reset_index(drop=True)  # Reverse Rows\n",
    "\n",
    "        # Always add the '# of Upsizes' column, regardless of peak acceleration\n",
    "        mapped_results_df.insert(0, '# of Upsizes', mapped_results_df.index)\n",
    "        \n",
    "        # Check if there are any rows where 'Peak Acceleration' is less than 0.5\n",
    "        filtered_df = mapped_results_df[mapped_results_df['Peak Acceleration'] < 0.5]\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            # If no values less than 0.5, return the full dataset\n",
    "            print(\"Infill Upsizing not possible (W36x925 reached)\")\n",
    "        else:\n",
    "            # Find the index where 'Peak Acceleration' first drops below 0.5\n",
    "            stop_index = filtered_df.index[0]\n",
    "            # Slice dataframe once PA dips under 0.5\n",
    "            mapped_results_df = mapped_results_df.loc[:stop_index]\n",
    "        \n",
    "        #Returns zeros if initial design passes for vibraitons\n",
    "        if mapped_results_df['Embodied Carbon Scaled'].iloc[-1] == initial_values_df['Embodied Carbon Scaled'][0]:\n",
    "            mapped_results_df[mapped_results_df.columns] = 0\n",
    "\n",
    "        return mapped_results_df\n",
    "\n",
    "    #-----------------------Girder Upsizing----------------------------------\n",
    "\n",
    "    def girder_upsizing(base_results):\n",
    "        \"\"\"\n",
    "        For intial designs expected to exceed the peak acceleration tolerance limit, girders are upsized until the limit is met\n",
    "\n",
    "        Parameters:\n",
    "        base_results (dict): Dictionary of all initial values used in design\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: DataFrame with the all girder upsizings mapped to values from all target matrices as new columns.\n",
    "        \"\"\"\n",
    "\n",
    "        #DataFrame of the EC Values\n",
    "        EC_dataframe = pd.DataFrame(np.where(base_results['Final Check'], base_results['Embodied Carbon Scaled'], np.nan),\n",
    "                                    index=base_results['Infill Sizes'].flatten(),\n",
    "                                    columns=base_results['Girder Sizes'].flatten())\n",
    "\n",
    "        # Check if EC_dataframe contains only NaN values\n",
    "        if EC_dataframe.isnull().all().all():\n",
    "            dummy_df = pd.DataFrame(0, index=range(1), columns=list(target_base_matrices.keys()) + ['# of Upsizes'])\n",
    "            return dummy_df\n",
    "\n",
    "        # Find the minimum value and its location\n",
    "        min_location = EC_dataframe.stack().idxmin()\n",
    "\n",
    "        # Convert row and column labels to integer indices\n",
    "        row_index = EC_dataframe.index.get_loc(min_location[0])  # Convert row label to index\n",
    "        col_index = EC_dataframe.columns.get_loc(min_location[1])  # Convert column label to index\n",
    "\n",
    "        # Create a DataFrame of the PhiMn Grouping\n",
    "        Grouping_dataframe = base_results['Groups Array']\n",
    "\n",
    "        #DataFrame of the PhiMn Grouping, with final check masking\n",
    "        Grouping_df = pd.DataFrame(\n",
    "            np.where(base_results['Final Check'], Grouping_dataframe, np.nan),\n",
    "            index=base_results['Infill Sizes'].flatten(),\n",
    "            columns=base_results['Girder Sizes'].flatten()\n",
    "        )\n",
    "\n",
    "        #Removes all columns to the right of the lowest observed EC value in matrix to begin Infill Upsizing\n",
    "        Grouping_df = Grouping_df.iloc[:, :col_index+1]\n",
    "\n",
    "        # Initialize a list to store the results\n",
    "        max_indices = []\n",
    "\n",
    "        # Iterate over each column to find the max value and its corresponding row\n",
    "        for col_idx, column_name in enumerate(Grouping_df.columns):\n",
    "            # Get the column data (drop NaN values)\n",
    "            column_data = Grouping_df[column_name].dropna()\n",
    "            \n",
    "            if not column_data.empty:\n",
    "                # Get max value and row index for this column\n",
    "                max_value = column_data.max()\n",
    "                row_label = column_data.idxmax()  # Row label corresponding to the max value\n",
    "                row_idx = Grouping_df.index.get_loc(row_label)  # Convert label to numeric index\n",
    "                max_indices.append((col_idx, row_idx, column_name, max_value))\n",
    "\n",
    "        # Convert the list to a DataFrame\n",
    "        max_indicies_df = pd.DataFrame(max_indices, columns=['ColIdx', 'RowIdx', 'ColumnName', 'MaxValue'])\n",
    "        \n",
    "        # Map the matrices using the updated function\n",
    "        mapped_results_df = map_to_matrices(max_indicies_df, target_base_matrices)\n",
    "\n",
    "        # Reverse the rows of the DataFrame\n",
    "        mapped_results_df = mapped_results_df[::-1].reset_index(drop=True)  # Reverse Rows\n",
    "\n",
    "        # Always add the '# of Upsizes' column, regardless of peak acceleration\n",
    "        mapped_results_df.insert(0, '# of Upsizes', mapped_results_df.index)\n",
    "\n",
    "        # Check if there are any rows where 'Peak Acceleration' is less than 0.5\n",
    "        filtered_df = mapped_results_df[mapped_results_df['Peak Acceleration'] < 0.5]\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            # If no values less than 0.5, return the full dataset\n",
    "            print(\"Girder Upsizing not possible (W36x925 reached)\")\n",
    "        else:\n",
    "            # Find the index where 'Peak Acceleration' first drops below 0.5\n",
    "            stop_index = filtered_df.index[0]\n",
    "            # Slice dataframe once PA dips under 0.5\n",
    "            mapped_results_df = mapped_results_df.loc[:stop_index]\n",
    "\n",
    "        #Returns zeros if initial design passes for vibrations\n",
    "        if mapped_results_df['Embodied Carbon Scaled'].iloc[-1] == initial_values_df['Embodied Carbon Scaled'][0]:\n",
    "            mapped_results_df[mapped_results_df.columns] = 0\n",
    "        \n",
    "        return mapped_results_df\n",
    "\n",
    "    #-----------------------Additional Concrete------------------------------\n",
    "\n",
    "    def concrete_upsizing(cap, step):\n",
    "        \"\"\"\n",
    "        For intial designs expected to exceed the peak acceleration tolerance limit, concrete is upsized until the limit is met\n",
    "\n",
    "        Parameters:\n",
    "        cap: maximum amount of concrete that can be added\n",
    "        step: interval size for how much concrete is added during each iteration\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: DataFrame with the all concrete upsizings mapped to values from all target matrices as new columns.\n",
    "        \"\"\"\n",
    "\n",
    "        if initial_values_df is None or initial_values_df['Peak Acceleration'].iloc[0] == 0:\n",
    "            dummy_df = pd.DataFrame(0, index=range(1), columns=target_base_matrices.keys())\n",
    "            return dummy_df\n",
    "        \n",
    "        if initial_values_df['Peak Acceleration'].iloc[0] <= 0.5:\n",
    "            return pd.DataFrame(0, index=range(1), columns=target_base_matrices.keys())\n",
    "\n",
    "        # Initialize a dictionary to store the results\n",
    "        all_mitigated_results = {}\n",
    "        \n",
    "        # Initialize a list to store peak accelerations for each iteration\n",
    "        peak_accelerations = []\n",
    "    \n",
    "        # Initialize an empty DataFrame to collect results\n",
    "        all_results_df = pd.DataFrame()\n",
    "\n",
    "        # Check Additional_Topping\n",
    "        Additional_Topping = 0\n",
    "\n",
    "        while Additional_Topping < cap:  # Cap in inches (5 inches = 100 iterations with step 0.1)\n",
    "\n",
    "            Additional_Topping += step  # Increment in inches\n",
    "            mitigated_results = mitigation_method(Additional_Topping - step)\n",
    "\n",
    "            if mitigated_results is None:\n",
    "                break    \n",
    "\n",
    "            # Store the mitigated results in the dictionary with the key being the Additional_Topping value\n",
    "            all_mitigated_results[Additional_Topping] = mitigated_results\n",
    "\n",
    "            EC_dataframe = pd.DataFrame(np.where(mitigated_results['Final Check'], mitigated_results['Embodied Carbon Scaled'], np.nan),\n",
    "                                         index=base_results['Infill Sizes'].flatten(),\n",
    "                                           columns=base_results['Girder Sizes'].flatten())\n",
    "\n",
    "            # Check if EC_dataframe contains only NaN values\n",
    "            if EC_dataframe.isnull().all().all():\n",
    "                if all_results_df.isnull().all().all():\n",
    "                    print(\"EC_dataframe contains only NaN values. Returning nothing.\")\n",
    "                    return None  # Exit gracefully and return nothing\n",
    "                else:\n",
    "                    return all_results_df\n",
    "            \n",
    "            # Find the minimum value and its location\n",
    "            min_location = EC_dataframe.stack().idxmin()\n",
    "\n",
    "            # Convert row and column labels to integer indices\n",
    "            row_index = EC_dataframe.index.get_loc(min_location[0])  # Convert row label to index\n",
    "            col_index = EC_dataframe.columns.get_loc(min_location[1])  # Convert column label to index\n",
    "\n",
    "            combined_mitigated_matrix = np.vectorize(lambda x, y: f\"Infill: {x}, Girder: {y}\")(mitigated_results['Infill Sizes'], mitigated_results['Girder Sizes'])\n",
    "\n",
    "            target_mitigated_matrices = {\n",
    "            \"Damping Ratio\": np.full((273, 273),base_results['DR'])[row_index, col_index],\n",
    "            \"Additional Topping\": Additional_Topping - step,\n",
    "            \"Peak Acceleration\": mitigated_results['Peak Acceleration'][row_index, col_index],\n",
    "            \"Embodied Carbon Scaled\": mitigated_results['Embodied Carbon Scaled'][row_index, col_index],\n",
    "            \"Selected Deck\": np.array(mitigated_results['Selected Deck']).flatten(),\n",
    "            \"Combined Sizes\": combined_mitigated_matrix[row_index, col_index],\n",
    "            \"Infill Sizes\": expand_infill(mitigated_results['Infill Sizes'].flatten())[row_index, col_index],\n",
    "            \"Infill Studs\": expand_infill(base_results['Studs II'])[row_index, col_index],\n",
    "            \"Infill Moment\": expand_infill(mitigated_results['M_FL_II'])[row_index, col_index],\n",
    "            \"Infill Moment Capcity\": expand_infill(mitigated_results['Phi_Mn_II'])[row_index, col_index],\n",
    "            \"Y1_II\": expand_infill(mitigated_results['Y1_II'])[row_index, col_index],\n",
    "            \"Y2_II\": expand_infill(mitigated_results['Y2_II'])[row_index, col_index],\n",
    "            \"Infill Contruction Load Deflection\": expand_infill(mitigated_results['DEF_Con_II'])[row_index, col_index],\n",
    "            \"Infill Camber\": expand_infill(mitigated_results['camber_II'])[row_index, col_index],\n",
    "            \"Infill Composite Dead Load Deflection\": expand_infill(mitigated_results['DEF_CDL_II'])[row_index, col_index],\n",
    "            \"Infill I_LB\": expand_infill(mitigated_results['I_LB_II'])[row_index, col_index],\n",
    "            \"Infill Composite Live Load Deflection\": expand_infill(mitigated_results['DEF_CLL_II'])[row_index, col_index],\n",
    "            \"Infill Composite Total Load Deflection\": expand_infill(mitigated_results['DEF_CTL_II'])[row_index, col_index],\n",
    "            \"Infill Case Label\": expand_girder(mitigated_results['Case Label II'])[row_index, col_index],\n",
    "            \"Girder Sizes\": expand_girder(mitigated_results['Girder Sizes'].flatten())[row_index, col_index],\n",
    "            \"Girder Studs\": expand_girder(base_results['Studs IG'])[row_index, col_index],\n",
    "            \"Girder Moment\": mitigated_results['M_FL_IG'][row_index, col_index],\n",
    "            \"Girder Moment Capcity\": expand_girder(mitigated_results['Phi_Mn_IG'])[row_index, col_index],\n",
    "            \"Y1_IG\": expand_girder(mitigated_results['Y1_IG'])[row_index, col_index],\n",
    "            \"Y2_IG\": expand_girder(mitigated_results['Y2_IG'])[row_index, col_index],\n",
    "            \"Girder Contruction Load Deflection\": mitigated_results['DEF_Con_IG'][row_index, col_index],\n",
    "            \"Girder Camber\": mitigated_results['camber_IG'][row_index, col_index],\n",
    "            \"Girder Composite Dead Load Deflection\": mitigated_results['DEF_CDL_IG'][row_index, col_index],\n",
    "            \"Girder I_LB\": expand_girder(mitigated_results['I_LB_IG'])[col_index],\n",
    "            \"Girder Composite Live Load Deflection\": expand_girder(mitigated_results['DEF_CLL_IG'])[row_index, col_index],\n",
    "            \"Girder Composite Total Load Deflection\": mitigated_results['DEF_CTL_IG'][row_index, col_index],\n",
    "            \"Girder Case Label\": expand_girder(mitigated_results['Case Label IG'])[row_index, col_index],\n",
    "            \"Total Topping\": mitigated_results[\"Total Topping\"],\n",
    "            \"Fundamental Frequency\": mitigated_results['Fundamental Frequency'][row_index, col_index],\n",
    "            }\n",
    "\n",
    "            # Use row_index and col_index as a mask to pull the value for peak acceleration or any other value\n",
    "            peak_acceleration = target_mitigated_matrices['Peak Acceleration']\n",
    "\n",
    "            # Convert the target mitigated matrices dictionary to a DataFrame for this iteration\n",
    "            temp_df = pd.DataFrame([target_mitigated_matrices])\n",
    "\n",
    "            # Append the current iteration's results to the all_results_df (stacking vertically)\n",
    "            all_results_df = pd.concat([all_results_df, temp_df], ignore_index=True)\n",
    "\n",
    "            if peak_acceleration < 0.5:\n",
    "                break\n",
    "            \n",
    "        return(all_results_df)\n",
    "\n",
    "    # Call Upsziing Defenitions\n",
    "    infill_upsizing_df = infill_upsizing(base_results)\n",
    "    girder_upsizing_df = girder_upsizing(base_results)\n",
    "    concrete_upsizing_df = concrete_upsizing(10, 0.25)\n",
    "\n",
    "    # Obtain objective values for initial and mitigated designs\n",
    "    initial_ec = initial_values_df['Embodied Carbon Scaled'][0]\n",
    "    infill_ec = infill_upsizing_df['Embodied Carbon Scaled'].iloc[-1]\n",
    "    girder_ec = girder_upsizing_df['Embodied Carbon Scaled'].iloc[-1]\n",
    "    concrete_ec = concrete_upsizing_df['Embodied Carbon Scaled'].iloc[-1]\n",
    "\n",
    "    initial_pa = initial_values_df['Peak Acceleration'][0]\n",
    "    infill_pa = infill_upsizing_df['Peak Acceleration'].iloc[-1]\n",
    "    girder_pa = girder_upsizing_df['Peak Acceleration'].iloc[-1]\n",
    "    concrete_pa = concrete_upsizing_df['Peak Acceleration'].iloc[-1]\n",
    "\n",
    "    # Obtain initial member values\n",
    "    initial_infill = initial_values_df['Infill Sizes'][0]\n",
    "    initial_infill_studs = initial_values_df['Infill Studs'][0]\n",
    "    initial_infill_camber = initial_values_df['Infill Camber'][0]\n",
    "    initial_girder = initial_values_df['Girder Sizes'][0]\n",
    "    initial_girder_studs = initial_values_df['Girder Studs'][0]\n",
    "    initial_girder_camber = initial_values_df['Girder Camber'][0]\n",
    "\n",
    "    # Assign EC penalty if peak acceleration limit isn't met\n",
    "    if infill_pa > 0.5:\n",
    "        infill_ec = float('inf')\n",
    "    if girder_pa > 0.5:\n",
    "        girder_ec = float('inf')\n",
    "    if concrete_pa > 0.5:\n",
    "        concrete_ec = float('inf')\n",
    "\n",
    "    # Assign controlling mitigation method to the 'best_method_df'\n",
    "    if (initial_ec != 0 and infill_ec == 0 and girder_ec == 0 and concrete_ec == 0) and (initial_pa <= 0.5):\n",
    "        condition_class = 1\n",
    "        #FILL THIS 'best_methods_df' DF BELOW with NaNs\n",
    "        best_method_df = initial_values_df\n",
    "        print_statement = \"Initial Design Works\"\n",
    "\n",
    "    elif (infill_ec != initial_ec and infill_ec != 0 and infill_ec <= min(girder_ec, concrete_ec)) and (infill_pa <= 0.5):\n",
    "        condition_class = 2\n",
    "        best_method_df = infill_upsizing_df\n",
    "        print_statement = \"Upsize Infills\"\n",
    "\n",
    "    elif (girder_ec != initial_ec and girder_ec != 0 and girder_ec <= min(infill_ec, concrete_ec)) and (girder_pa <= 0.5):\n",
    "        condition_class = 3\n",
    "        best_method_df = girder_upsizing_df\n",
    "        print_statement = \"Upsize Girders\"\n",
    "\n",
    "    elif (concrete_ec != initial_ec and concrete_ec != 0 and concrete_ec <= min(infill_ec, girder_ec)) and (concrete_pa <= 0.5):\n",
    "        condition_class = 4\n",
    "        best_method_df = concrete_upsizing_df\n",
    "        print_statement = \"Add Concrete Topping\"\n",
    "\n",
    "    else:\n",
    "        condition_class = 5\n",
    "        #FILL THIS 'best_methods_df' DF BELOW with NaNs\n",
    "        best_method_df = initial_values_df\n",
    "        print_statement = \"No Possible Design\"\n",
    "\n",
    "    print(print_statement,\n",
    "          '\\n' + 'Initial Infill: ' + str(initial_infill) + ' ' + str(initial_infill_studs.astype(int)) + ' c= ' + str(initial_infill_camber[0]) + '\\n' +\n",
    "          'Initial Girder: ' + str(initial_girder) + ' [' + str(initial_girder_studs.astype(int)) + '] c= ' + str(initial_girder_camber) + '\\n' +\n",
    "          'Initial Deck and Topping: ' + str(base_results['Selected Deck']) + '\\n' +\n",
    "          'Initial Peak Acceleration: ' + str(initial_pa) + '\\n' +\n",
    "          'Initial Scaled EC: ' + str(initial_ec) + '\\n' +\n",
    "          'Mitigated Infill: ' + str(best_method_df['Infill Sizes'].iloc[-1]) + ' ' + str(best_method_df['Infill Studs'].iloc[-1].astype(int)) + ' c= ' + str(best_method_df['Infill Camber'].iloc[-1].astype(int)[0]) + '\\n' +\n",
    "          'Mitigated Girder: ' + str(best_method_df['Girder Sizes'].iloc[-1]) + ' [' + str(best_method_df['Girder Studs'].iloc[-1].astype(int)) + '] c= ' + str(best_method_df['Girder Camber'].iloc[-1]) + '\\n' +\n",
    "          'Mitigated Peak Acceleration: ' + str(best_method_df['Peak Acceleration'].iloc[-1]) + '\\n' +\n",
    "          'Mitigated Scaled EC: ' + str(best_method_df['Embodied Carbon Scaled'].iloc[-1])\n",
    "          )\n",
    "\n",
    "    return\n",
    "\n",
    "sizer_and_calc(Girder_Span, Infill_Span, NumInfill, Conc_Type_num, Deck_Type, Building_Use_num, percent_comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
